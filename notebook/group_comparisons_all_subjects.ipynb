{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import different packages to be used\n",
    "from neurodsp.spectral import compute_spectrum, rotate_powerlaw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from fooof import FOOOFGroup\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import pingouin as pg\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract eeg data and somno scoring from each subject of interest\n",
    "\n",
    "# Function to load EEG and somno scoring CSV files for a given subject\n",
    "def load_data(subject_id):\n",
    "    eeg_data = pd.read_csv(input(f\"Enter location of CSV file for {subject_id} which includes EEG for somnotate scoring: \"))\n",
    "    somno_scoring = pd.read_csv(input(f\"Enter location of file for {subject_id} of the somnotate scoring converted back to CSV: \"))\n",
    "    return eeg_data, somno_scoring\n",
    "\n",
    "# Load data for subjects\n",
    "eeg_data_sub_007, somno_scoring_sub_007 = load_data(\"sub-007\")\n",
    "eeg_data_sub_010, somno_scoring_sub_010 = load_data(\"sub-010\")\n",
    "eeg_data_sub_011, somno_scoring_sub_011 = load_data(\"sub-011\")\n",
    "eeg_data_sub_015, somno_scoring_sub_015 = load_data(\"sub-015\")\n",
    "eeg_data_sub_016, somno_scoring_sub_016 = load_data(\"sub-016\")\n",
    "eeg_data_sub_017, somno_scoring_sub_017 = load_data(\"sub-017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the EEG data and somno scoring as pickle files\n",
    "\n",
    "eeg_data_sub_007.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/eeg_data_sub-007_ses-01_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-007 saved as pickle file\")\n",
    "somno_scoring_sub_007.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-007_ses-01_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-007 saved as pickle file\")\n",
    "eeg_data_sub_010.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno//eeg_data_sub-010_ses-01_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-010 saved as pickle file\")\n",
    "somno_scoring_sub_010.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-010_ses-01_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-010 saved as pickle file\")\n",
    "eeg_data_sub_011.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/eeg_data_sub-011_ses-01_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-011 saved as pickle file\")\n",
    "somno_scoring_sub_011.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-011_ses-01_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-011 saved as pickle file\")\n",
    "eeg_data_sub_015.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/eeg_data_sub-015_ses-01_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-015 saved as pickle file\")\n",
    "somno_scoring_sub_015.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-015_ses-01_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-015 saved as pickle file\")\n",
    "eeg_data_sub_016.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/eeg_data_sub-016_ses-02_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-016 saved as pickle file\")\n",
    "somno_scoring_sub_016.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-016_ses-02_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-016 saved as pickle file\")\n",
    "eeg_data_sub_017.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/eeg_data_sub-017_ses-01_recording-01.pkl\")\n",
    "print(\"eeg_data_sub-017 saved as pickle file\")\n",
    "somno_scoring_sub_017.to_pickle(\"Z:/somnotate/to_score_set/pickle_eeg_somno/somno_scoring_sub-017_ses-01_recording-01.pkl\")\n",
    "print(\"somno_scoring_sub-017 saved as pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "# Set sampling rate\n",
    "fs = int(input(\"Sampling rate of signal in Hz: \"))\n",
    "\n",
    "# State duration for exponent analysis\n",
    "epoch_duration = int(input(\"Enter length of epoch for exponent analysis in seconds: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use neurodsp to determine the PSD for both channels at the epoch of interest in each subject\n",
    "\n",
    "# Define a small number (epsilon) to add to 0 values\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Specify the channels of interest\n",
    "channels_of_interest = ['EEG1', 'EEG2']\n",
    "\n",
    "# Function to calculate the PSD for each subject, focusing on specific channels\n",
    "def calculate_psd(eeg_data, fs, epoch_duration, target_channels):\n",
    "    # Prepare a dictionary to store PSD values and frequency data for each channel\n",
    "    psd_values_dict = {}\n",
    "    frequencies = None  # Frequencies are the same for each bin\n",
    "\n",
    "    # Loop over each EEG channel, filtered by target channels\n",
    "    for channel, sig in eeg_data.items():\n",
    "        if channel not in target_channels:\n",
    "            continue  # Skip channels not in the list\n",
    "        \n",
    "        # Initialize a list to store PSD values for the current channel\n",
    "        psd_values_dict[channel] = []\n",
    "\n",
    "        # Calculate total recording time in seconds and number of bins\n",
    "        recording_seconds = len(sig) / fs  # Assuming all channels have the same length\n",
    "        num_bins = int(recording_seconds // epoch_duration)  # For the entirety of recording length\n",
    "        samples_per_bin = fs * epoch_duration\n",
    "\n",
    "        # Loop over each bin\n",
    "        for i in range(num_bins):\n",
    "            # Extract the data for the current bin\n",
    "            start = i * samples_per_bin\n",
    "            end = start + samples_per_bin\n",
    "            bin_data = sig[start:end]\n",
    "            \n",
    "            # Compute the power spectrum for this bin using Welch's method\n",
    "            freqs, psd = compute_spectrum(bin_data, fs, method='welch', avg_type='mean', nperseg=fs*2)\n",
    "            \n",
    "            # Store the PSD values\n",
    "            psd_values_dict[channel].append(psd)\n",
    "            \n",
    "            # Store frequencies once (frequencies are the same for all bins)\n",
    "            if frequencies is None:\n",
    "                frequencies = freqs\n",
    "\n",
    "    # Convert psd_values to NumPy arrays for easier handling\n",
    "    for channel in psd_values_dict:\n",
    "        psd_values_dict[channel] = np.array(psd_values_dict[channel])\n",
    "        \n",
    "        # Replace zeros with epsilon for all PSD values\n",
    "        psd_values_dict[channel][psd_values_dict[channel] == 0] = epsilon\n",
    "\n",
    "    return psd_values_dict, frequencies\n",
    "\n",
    "# Assume we have EEG data for multiple subjects\n",
    "subjects_data = {\n",
    "    'sub-007': eeg_data_sub_007,\n",
    "    'sub-010': eeg_data_sub_010,\n",
    "    'sub-011': eeg_data_sub_011,\n",
    "    'sub-015': eeg_data_sub_015,\n",
    "    'sub-016': eeg_data_sub_016,\n",
    "    'sub-017': eeg_data_sub_017\n",
    "}\n",
    "\n",
    "all_psd_values = {}\n",
    "\n",
    "# Loop over each subject's EEG data and calculate the PSD\n",
    "for subject_id, eeg_data in subjects_data.items():\n",
    "    psd_values, frequencies = calculate_psd(eeg_data, fs, epoch_duration)\n",
    "    all_psd_values[subject_id] = psd_values\n",
    "\n",
    "# Example of how to access the PSD for a particular subject and channel\n",
    "psd_values_sub_010_eeg1 = all_psd_values['sub-010']['EEG1']\n",
    "psd_values_sub_010_eeg2 = all_psd_values['sub-010']['EEG2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run all channels and all subjects through FOOOF modelling\n",
    "\n",
    "# Parameters for FOOOF fitting\n",
    "fooof_params = {\n",
    "    'peak_width_limits': [1.0, 8.0],\n",
    "    'max_n_peaks': 6,\n",
    "    'min_peak_height': 0.1,\n",
    "    'peak_threshold': 2.0,\n",
    "    'aperiodic_mode': 'fixed'\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store FOOOF results for all subjects\n",
    "fooof_results = {}\n",
    "\n",
    "# Loop over each subject's PSD values\n",
    "for subject_id, psd_values in all_psd_values.items():\n",
    "    fooof_results[subject_id] = {}  # Create an entry for the subject\n",
    "    \n",
    "    # Loop over each channel's PSD values\n",
    "    for channel, psd_matrix in psd_values.items():\n",
    "        # Skip EMG channel and sleepStage column\n",
    "        if channel in ['EMG', 'sleepStage']:\n",
    "            print(f\"Skipping {channel} for subject {subject_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Initialize a FOOOFGroup object with specified parameters\n",
    "        fg = FOOOFGroup(**fooof_params)\n",
    "        \n",
    "        # Fit FOOOF model across the matrix of power spectra for this channel\n",
    "        fg.fit(frequencies, psd_matrix, [2, 40])\n",
    "        \n",
    "        # Store the FOOOFGroup object for this channel\n",
    "        fooof_results[subject_id][channel] = fg\n",
    "\n",
    "# Example: Accessing results\n",
    "# To get the FOOOF results for sub-007, EEG1:\n",
    "fg_sub_007_eeg1 = fooof_results['sub-007']['EEG1']\n",
    "\n",
    "# Print or save the FOOOF results for all subjects and channels\n",
    "for subject_id, channel_results in fooof_results.items():\n",
    "    print(f\"Subject: {subject_id}\")\n",
    "    for channel, fg in channel_results.items():\n",
    "        print(f\"  Channel: {channel}\")\n",
    "        print(f\"    {fg.get_results()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the FOOOF model fitting results as pickle files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the average aperiodic component for each of the subjects of interest\n",
    "\n",
    "# Initialize a dictionary to store average exponents for each subject\n",
    "avg_exps_all_subjects = {}\n",
    "\n",
    "# Loop over each subject's FOOOF results\n",
    "for subject_id, channel_results in fooof_results.items():\n",
    "    exponents = []  # List to collect exponents from all channels for this subject\n",
    "    \n",
    "    for channel, fg in channel_results.items():\n",
    "        # Extract the aperiodic exponent for the current channel\n",
    "        exps = fg.get_params('aperiodic_params', 'exponent')\n",
    "        exponents.append(exps)\n",
    "    \n",
    "    # Calculate the average exponent across channels\n",
    "    avg_exps_all_subjects[subject_id] = np.mean(exponents, axis=0)\n",
    "\n",
    "# Example: Accessing avg_exps for a specific subject\n",
    "avg_exps_sub_007 = avg_exps_all_subjects['sub-007']\n",
    "avg_exps_sub_010 = avg_exps_all_subjects['sub-010']\n",
    "avg_exps_sub_011 = avg_exps_all_subjects['sub-011']\n",
    "\n",
    "# Print the results for verification\n",
    "for subject_id, avg_exps in avg_exps_all_subjects.items():\n",
    "    print(f\"Subject: {subject_id}, Average Exponent: {avg_exps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert somno scoring from each subject into the required epoch period to match exponent\n",
    "\n",
    "# List of subjects and their corresponding somno_scoring DataFrames\n",
    "subjects = {\n",
    "    \"sub-007\": somno_scoring_sub_007,\n",
    "    \"sub-010\": somno_scoring_sub_010,\n",
    "    \"sub-011\": somno_scoring_sub_011,\n",
    "}\n",
    "\n",
    "# Dictionary to store processed somno scoring for each subject\n",
    "processed_somno_scoring = {}\n",
    "\n",
    "# Loop through each subject\n",
    "for subject_id, somno_df in subjects.items():\n",
    "    \n",
    "    # Calculate total recording seconds\n",
    "    recording_seconds = len(somno_df) / fs\n",
    "   \n",
    "    # Ensure the Timestamp column is in datetime format\n",
    "    somno_df[\"Timestamp\"] = pd.to_datetime(somno_df[\"Timestamp\"])\n",
    "\n",
    "    # Define the expected range of timestamps (1 Hz for the entire duration)\n",
    "    start_time_data = somno_df[\"Timestamp\"].iloc[0]\n",
    "    end_time = start_time_data + pd.Timedelta(seconds=int(recording_seconds)) - pd.Timedelta(seconds=1)\n",
    "    expected_timestamps = pd.date_range(start=start_time_data, end=end_time, freq=\"1S\")\n",
    "\n",
    "    # Convert timestamps to seconds relative to the first timestamp\n",
    "    somno_df[\"second\"] = (somno_df[\"Timestamp\"] - start_time_data).dt.total_seconds().astype(int)\n",
    "\n",
    "    # Downsample by taking the mode of sleepStage and the first timestamp in each second\n",
    "    downsampled_df = somno_df.groupby(\"second\").agg({\n",
    "        \"Timestamp\": \"first\",  # Take the first timestamp in each group\n",
    "        \"sleepStage\": lambda x: x.mode().iloc[0] if not x.mode().empty else None  # Mode for sleepStage\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    # Round the Timestamp column to the nearest second\n",
    "    downsampled_df[\"Timestamp\"] = downsampled_df[\"Timestamp\"].dt.round(\"S\")\n",
    "\n",
    "    # Reindex to align with the expected timestamps\n",
    "    downsampled_df = downsampled_df.set_index(\"Timestamp\")\n",
    "    downsampled_df = downsampled_df.reindex(expected_timestamps)\n",
    "    downsampled_df = downsampled_df.reset_index().rename(columns={\"index\": \"Timestamp\"})\n",
    "\n",
    "    # Fill in missing sleepStage values if necessary\n",
    "    downsampled_df[\"sleepStage\"] = downsampled_df[\"sleepStage\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    downsampled_df[\"sleepStage\"] = downsampled_df[\"sleepStage\"].astype(int)\n",
    "\n",
    "    # Convert to epoch_duration\n",
    "    grouped = (\n",
    "        downsampled_df.groupby(downsampled_df.index // epoch_duration)\n",
    "        .agg({\n",
    "            \"Timestamp\": \"first\",  # Take the value at the start of the epoch for Timestamp\n",
    "            \"sleepStage\": lambda x: x.mode().iloc[0] if not x.mode().empty else None  # Mode for sleepStage\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # Reset index for a clean output\n",
    "    subset_df = grouped.reset_index(drop=True)\n",
    "    subset_df[\"Timestamp\"] = subset_df[\"Timestamp\"].dt.round(\"10S\")\n",
    "\n",
    "    # Store the processed DataFrame for the current subject\n",
    "    processed_somno_scoring[subject_id] = subset_df\n",
    "\n",
    "    # Display results for each subject\n",
    "    print(f\"Processed somno scoring for {subject_id}:\")\n",
    "    print(subset_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the avg_exps from each subject as an extra column to the processed somno scoring\n",
    "\n",
    "# Ensure avg_exps is stored in a dictionary with the corresponding subject IDs\n",
    "avg_exps_dict = {\n",
    "    \"sub-007\": avg_exps_sub_007,\n",
    "    \"sub-010\": avg_exps_sub_010,\n",
    "    \"sub-011\": avg_exps_sub_011,\n",
    "}\n",
    "\n",
    "# Loop through each subject\n",
    "for subject_id, subset_df in processed_somno_scoring.items():\n",
    "    # Retrieve the avg_exps array for the subject\n",
    "    avg_exps = avg_exps_dict[subject_id]\n",
    "    \n",
    "    # Check if lengths match\n",
    "    if len(avg_exps) == len(subset_df):\n",
    "        # Add avg_exps as a new column\n",
    "        subset_df[\"avg_exps\"] = avg_exps\n",
    "        print(f\"Added avg_exps to {subject_id} processed somno scoring.\")\n",
    "    else:\n",
    "        print(f\"Length mismatch for {subject_id}: avg_exps ({len(avg_exps)}) vs subset_df ({len(subset_df)})\")\n",
    "\n",
    "    # Save the updated DataFrame back to the dictionary\n",
    "    processed_somno_scoring[subject_id] = subset_df\n",
    "\n",
    "# Verify the updated processed_somno_scoring\n",
    "for subject_id, subset_df in processed_somno_scoring.items():\n",
    "    print(f\"Processed somno scoring for {subject_id}:\")\n",
    "    print(subset_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a combined df for visualising and stats for all subjects and stages\n",
    "\n",
    "# Add the subject name to each individual dataframe before concatenating\n",
    "processed_somno_scoring[\"sub-007\"]['subject'] = 'sub-007'\n",
    "processed_somno_scoring[\"sub-010\"]['subject'] = 'sub-010'\n",
    "processed_somno_scoring[\"sub-011\"]['subject'] = 'sub-011'\n",
    "\n",
    "# Combine processed somno scoring data from all subjects into a single DataFrame\n",
    "combined_df = pd.concat(\n",
    "    [processed_somno_scoring[\"sub-007\"], processed_somno_scoring[\"sub-010\"], processed_somno_scoring[\"sub-011\"]],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional choice for removing negative exponent values\n",
    "\n",
    "# Remove rows where avg_exps is less than 0\n",
    "filtered_combined_df = combined_df[combined_df['avg_exps'] >= 0]\n",
    "\n",
    "# Find and print rows where avg_exps was less than 0\n",
    "invalid_rows = combined_df[combined_df['avg_exps'] < 0]\n",
    "print(\"The following avg_exp values were below zero and removed for plotting and group comparisons\")\n",
    "for index, row in invalid_rows.iterrows():\n",
    "    print(f\"Subject: {row['subject']}, avg_exps: {row['avg_exps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert ZT column into combined df\n",
    "\n",
    "def add_zt_column(df, timestamp_col=\"Timestamp\", reference_time=\"09:00:00\"):\n",
    "    \"\"\"\n",
    "    Add a Zeitgeber Time (ZT) column to a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame containing a timestamp column.\n",
    "    - timestamp_col (str): Name of the timestamp column. Default is \"Timestamp\".\n",
    "    - reference_time (str): Time of day (HH:MM:SS) to use as ZT=0. Default is \"09:00:00\".\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added \"ZT\" column.\n",
    "    \"\"\"\n",
    "    # Ensure the timestamp column is in datetime format\n",
    "    df = df.copy()  # Work on a copy to avoid modifying the original DataFrame\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "    \n",
    "    # Define ZT=0 as reference_time on the first day\n",
    "    start_zt = pd.to_datetime(f\"{df[timestamp_col].iloc[0].date()} {reference_time}\")\n",
    "    \n",
    "    # Calculate Zeitgeber Time (ZT)\n",
    "    df[\"ZT\"] = (df[timestamp_col] - start_zt).dt.total_seconds() / 3600  # Convert seconds to hours\n",
    "    \n",
    "    # Adjust ZT to be between 0 and 24 hours\n",
    "    df[\"ZT\"] = df[\"ZT\"] % 24\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df_zt = add_zt_column(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot all exponent value of each subject in each sleep stage of filtered exponents which have excluded negative values\n",
    "\n",
    "# Ensure the sleepStage column is of categorical type\n",
    "filtered_combined_df['sleepStage'] = filtered_combined_df['sleepStage'].astype('category')\n",
    "\n",
    "# Assuming filtered_combined_df is already available\n",
    "# Convert sleepStage to a numeric type to allow addition\n",
    "filtered_combined_df['sleepStage_numeric'] = filtered_combined_df['sleepStage'].cat.codes\n",
    "\n",
    "# Apply jitter to the numeric sleepStage values to spread out the markers horizontally\n",
    "jitter_strength = 0.3  # Controls how much to spread out the points\n",
    "filtered_combined_df['sleepStage_jittered'] = (\n",
    "    filtered_combined_df['sleepStage_numeric'] \n",
    "    + np.random.uniform(-jitter_strength, jitter_strength, size=len(filtered_combined_df))\n",
    ")\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot with 'sleepStage_jittered' on the x-axis, 'avg_exps' on the y-axis, and 'subject' as hue\n",
    "sns.scatterplot(\n",
    "    data=filtered_combined_df, \n",
    "    x='sleepStage_jittered', \n",
    "    y='avg_exps', \n",
    "    hue='subject', \n",
    "    palette='Set1', \n",
    "    s=50,           # Adjust marker size to make them smaller\n",
    "    marker='o', \n",
    "    edgecolor='black', \n",
    "    alpha=0.5       # Make markers more transparent\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Exponent Value (a.u.)', fontsize=14)\n",
    "plt.xlabel('')  # Remove x-axis label\n",
    "plt.title('1/f Exponent by Sleep Stage', fontsize=16)\n",
    "\n",
    "# Customize x-ticks to be 1, 2, and 3 for sleep stages\n",
    "plt.xticks([0, 1, 2], ['Awake', 'NREM', 'REM'])\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Show legend for subjects with adjusted placement\n",
    "plt.legend(title=\"Subjects\", loc='upper right', fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot all exponent value in an epoch of each subject in each sleep stage which are not filtered for negative values\n",
    "\n",
    "# Identify continuous sleepStage bouts\n",
    "combined_df_zt['bout_group'] = (combined_df_zt['sleepStage'] != combined_df_zt['sleepStage'].shift()).cumsum()\n",
    "\n",
    "# Group by sleepStage and bout_group, and calculate average exponent value for each bout\n",
    "bout_avg_exp = (\n",
    "    combined_df_zt.groupby(['subject', 'sleepStage', 'bout_group'])['avg_exps']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Map sleepStage to readable labels\n",
    "stage_labels = {1: 'Awake', 2: 'NREM', 3: 'REM'}\n",
    "bout_avg_exp['stage'] = bout_avg_exp['sleepStage'].map(stage_labels)\n",
    "\n",
    "# Calculate the mean for each stage\n",
    "stage_means = bout_avg_exp.groupby('stage')['avg_exps'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(\n",
    "    data=bout_avg_exp,\n",
    "    x='stage',\n",
    "    y='avg_exps',\n",
    "    hue='subject',  # Different colors for each subject\n",
    "    palette='Set1',\n",
    "    dodge=True,  # To separate points slightly if multiple subjects share the same stage\n",
    "    alpha=0.5,\n",
    "    size=5,  # Smaller point size for better visibility\n",
    "    jitter=0.5,  # Randomly jitter points to avoid exact overlap\n",
    ")\n",
    "\n",
    "# Add horizontal lines for the mean exponent value for each stage\n",
    "for i, row in stage_means.iterrows():\n",
    "    plt.hlines(y=row['avg_exps'], xmin=i-0.5, xmax=i+0.5, colors='k', linewidth=5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('1/f Exponent in Bout Across Sleep Stages ')\n",
    "plt.legend(title='Subject')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Run ANOVA comparing exponent values across sleep stages\n",
    "# Extract exponent values for each stage\n",
    "awake_data = bout_avg_exp[bout_avg_exp['stage'] == 'Awake']['avg_exps']\n",
    "nrem_data = bout_avg_exp[bout_avg_exp['stage'] == 'NREM']['avg_exps']\n",
    "rem_data = bout_avg_exp[bout_avg_exp['stage'] == 'REM']['avg_exps']\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_stat, p_value = stats.f_oneway(awake_data, nrem_data, rem_data)\n",
    "\n",
    "# If ANOVA is significant, run Tukey's HSD for post-hoc analysis\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in exponent values across sleep stages. Performing Tukey's HSD post-hoc test...\")\n",
    "\n",
    "    # Prepare the data for Tukey's HSD test\n",
    "    bout_avg_exp['stage'] = bout_avg_exp['stage'].astype('category')  # Make stage a categorical variable for Tukey's HSD\n",
    "    tukey_result = pairwise_tukeyhsd(\n",
    "        bout_avg_exp['avg_exps'],  # Dependent variable\n",
    "        bout_avg_exp['stage'],     # Independent variable (sleep stage)\n",
    "        alpha=0.05                # Significance level\n",
    "    )\n",
    "\n",
    "    # Display Tukey's HSD result\n",
    "    print(tukey_result.summary())\n",
    "else:\n",
    "    print(\"There is no significant difference in exponent values across sleep stages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate mean/error and complete anova comparisons when combining all subjects\n",
    "\n",
    "# Group by sleepStage and calculate mean and standard error for avg_exps\n",
    "summary_stats = combined_df.groupby(\"sleepStage\")[\"avg_exps\"].agg(\n",
    "    mean=\"mean\",\n",
    "    sem=lambda x: np.std(x, ddof=1) / np.sqrt(len(x))  # Standard error\n",
    ").reset_index()\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the combined dataframe has sleepStage and avg_exps columns\n",
    "# Perform ANOVA across the three sleep stages\n",
    "anova_results = stats.f_oneway(\n",
    "    combined_df[combined_df[\"sleepStage\"] == 1][\"avg_exps\"],  # Stage 1 data\n",
    "    combined_df[combined_df[\"sleepStage\"] == 2][\"avg_exps\"],  # Stage 2 data\n",
    "    combined_df[combined_df[\"sleepStage\"] == 3][\"avg_exps\"]   # Stage 3 data\n",
    ")\n",
    "\n",
    "# Print the results of the ANOVA\n",
    "print(\"ANOVA Results:\")\n",
    "print(f\"F-statistic: {anova_results.statistic}\")\n",
    "print(f\"P-value: {anova_results.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming combined_df has 'sleepStage' and 'avg_exps' columns with data from all subjects\n",
    "\n",
    "# Perform Tukey's HSD test for multiple comparisons\n",
    "tukey_results = pairwise_tukeyhsd(\n",
    "    combined_df['avg_exps'],  # The dependent variable\n",
    "    combined_df['sleepStage'],  # The independent variable (grouping variable)\n",
    "    alpha=0.05  # Significance level\n",
    ")\n",
    "\n",
    "# Print the results of Tukey's HSD test\n",
    "print(tukey_results.summary())\n",
    "\n",
    "# If you want to extract the specific results into a DataFrame for easier interpretation\n",
    "tukey_df = pd.DataFrame(data=tukey_results.summary().data[1:], columns=tukey_results.summary().data[0])\n",
    "print(tukey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot boxplot running ANOVA and plotting individual significant comparisons\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "sleep_stages = combined_df_zt['sleepStage'].unique()\n",
    "avg_exps_by_stage = [combined_df_zt.loc[combined_df_zt['sleepStage'] == stage, 'avg_exps'] for stage in sleep_stages]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_value, p_value = f_oneway(*avg_exps_by_stage)\n",
    "\n",
    "print(f'One-way ANOVA results: F={f_value:.4f}, p={p_value:.4f}')\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define lighter versions of red, blue, and green\n",
    "box_colors = ['lightcoral', 'lightskyblue', 'lightgreen']  # Lighter color options\n",
    "\n",
    "# Define properties for outliers (make them more transparent)\n",
    "flierprops = dict(marker='o', color='gray', alpha=0.4, markersize=5)\n",
    "\n",
    "# Create the boxplot with custom colors\n",
    "sns.boxplot(\n",
    "    data=combined_df_zt, \n",
    "    x='sleepStage', \n",
    "    y='avg_exps', \n",
    "    palette=box_colors,  # Use the custom color palette\n",
    "    showfliers=True, \n",
    "    width=0.5,  # Adjust box width to make them more compact\n",
    "    linewidth=2.5,\n",
    "    flierprops=flierprops\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Exponent Value (a.u.)', fontsize=14)\n",
    "plt.xlabel('')  # Remove x-axis label\n",
    "plt.title('1/f Exponent in each Epoch Across Sleep Stage', fontsize=16)\n",
    "\n",
    "# Customize x-ticks to be 1, 2, and 3 for sleep stages\n",
    "plt.xticks([0, 1, 2], ['Awake', 'NREM', 'REM'])\n",
    "\n",
    "# Perform post-hoc pairwise comparisons using Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=combined_df_zt['avg_exps'], groups=combined_df_zt['sleepStage'], alpha=0.05)\n",
    "\n",
    "# Plot significant differences\n",
    "y_offset = 0.5  # Initialize y-offset\n",
    "for row in tukey._results_table.data[1:]:  # Skip the header row\n",
    "    p_value = float(row[3])  # Get p-value\n",
    "    group1, group2 = row[0], row[1]\n",
    "    x1 = sleep_stages.tolist().index(group1)\n",
    "    x2 = sleep_stages.tolist().index(group2)\n",
    "    y = np.max(combined_df_zt['avg_exps']) + y_offset  # y-coordinate for the asterisk\n",
    "    \n",
    "    # Determine number of asterisks based on p-value\n",
    "    if p_value < 0.001:\n",
    "        asterisks = '***'\n",
    "    elif p_value < 0.01:\n",
    "        asterisks = '**'\n",
    "    elif p_value < 0.05:\n",
    "        asterisks = '*'\n",
    "    else:\n",
    "        asterisks = ''\n",
    "    \n",
    "    plt.plot([x1, x2], [y, y], 'k-', lw=1)  # Line connecting the two groups\n",
    "    plt.text((x1 + x2) / 2, y, asterisks, ha='center', va='bottom', fontsize=14)\n",
    "    \n",
    "    y_offset -= 0.2  # Decrease y-offset for each comparison\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  # Get current axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Z:/volkan/fooof/figures/stage_comparison/all_sub_boxplot_ANOVA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot all exponent value in an epoch of each subject in each sleep stage which are not filtered for negative values - one-way ANOVA and comparisons\n",
    "\n",
    "# Identify continuous sleepStage bouts\n",
    "combined_df_zt['bout_group'] = (combined_df_zt['sleepStage'] != combined_df_zt['sleepStage'].shift()).cumsum()\n",
    "\n",
    "# Group by sleepStage and bout_group, and calculate average exponent value for each bout\n",
    "bout_avg_exp = (\n",
    "    combined_df_zt.groupby(['subject', 'sleepStage', 'bout_group'])['avg_exps']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Map sleepStage to readable labels\n",
    "stage_labels = {1: 'Awake', 2: 'NREM', 3: 'REM'}\n",
    "bout_avg_exp['stage'] = bout_avg_exp['sleepStage'].map(stage_labels)\n",
    "\n",
    "# Calculate the mean for each stage\n",
    "stage_means = bout_avg_exp.groupby('stage')['avg_exps'].mean().reset_index()\n",
    "\n",
    "# Perform one-way ANOVA using scipy's f_oneway\n",
    "anova_result = stats.f_oneway(\n",
    "    bout_avg_exp[bout_avg_exp['stage'] == 'Awake']['avg_exps'],\n",
    "    bout_avg_exp[bout_avg_exp['stage'] == 'NREM']['avg_exps'],\n",
    "    bout_avg_exp[bout_avg_exp['stage'] == 'REM']['avg_exps']\n",
    ")\n",
    "\n",
    "# Print ANOVA results\n",
    "print(\"ANOVA Results:\")\n",
    "print(f\"F-statistic: {anova_result.statistic:.3f}\")\n",
    "print(f\"p-value: {anova_result.pvalue:.3e}\")\n",
    "\n",
    "# Check if ANOVA is significant\n",
    "if anova_result.pvalue < 0.05:  # If p-value is less than 0.05, perform Tukey HSD\n",
    "    # Perform Tukey HSD post-hoc test\n",
    "    tukey_results = pairwise_tukeyhsd(endog=bout_avg_exp['avg_exps'], groups=bout_avg_exp['stage'], alpha=0.05)\n",
    "    \n",
    "    # Print Tukey HSD results\n",
    "    print(\"\\nTukey HSD Results:\")\n",
    "    print(tukey_results.summary())\n",
    "    \n",
    "    # Create a dictionary to store significance\n",
    "    significance_dict = {}\n",
    "    for comparison in tukey_results.summary().data[1:]:\n",
    "        group1, group2 = comparison[0], comparison[1]\n",
    "        p_value = comparison[3]\n",
    "        if p_value < 0.001:\n",
    "            significance_dict[(group1, group2)] = '***'\n",
    "        elif p_value < 0.01:\n",
    "            significance_dict[(group1, group2)] = '**'\n",
    "        elif p_value < 0.05:\n",
    "            significance_dict[(group1, group2)] = '*'\n",
    "else:\n",
    "    significance_dict = {}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Overlay the stripplot to show individual points\n",
    "sns.stripplot(\n",
    "    data=bout_avg_exp,\n",
    "    x='stage',\n",
    "    y='avg_exps',\n",
    "    hue='subject',  # Different colors for each subject\n",
    "    palette='Set1',\n",
    "    dodge=True,  # Separate points slightly if multiple subjects share the same stage\n",
    "    alpha=0.3,\n",
    "    size=5,  # Adjust dot size for better visibility\n",
    "    jitter=0.4,  # Adjust jitter for variation in horizontal positioning\n",
    ")\n",
    "\n",
    "# Add X markers at the mean exponent value for each stage\n",
    "stage_means = bout_avg_exp.groupby('stage')['avg_exps'].mean().reset_index()\n",
    "for i, row in stage_means.iterrows():\n",
    "    # Plot \"X\" markers at the mean value for each stage\n",
    "    plt.scatter(x=i, y=row['avg_exps'], color='k', marker='x', s=100)\n",
    "\n",
    "# Add significance asterisks between groups based on Tukey HSD\n",
    "for (group1, group2), significance in significance_dict.items():\n",
    "    x1 = list(stage_labels.values()).index(group1)\n",
    "    x2 = list(stage_labels.values()).index(group2)\n",
    "    y_max = max(bout_avg_exp[bout_avg_exp['stage'] == group1]['avg_exps'].max(), \n",
    "                bout_avg_exp[bout_avg_exp['stage'] == group2]['avg_exps'].max()) + 0.1\n",
    "    # Plot the bar (line) between the two groups\n",
    "    plt.plot([x1, x2], [y_max, y_max], color='k', lw=1.5)\n",
    "    plt.text((x1 + x2) / 2, y_max, significance, ha='center', va='bottom', fontsize=20, color='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('1/f Exponent in Each Bout Across Sleep Stages')\n",
    "plt.legend(title='Subject')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare different conditions for avg_exp value\n",
    "\n",
    "# Filter data for light and dark periods\n",
    "light_data = combined_df_zt[(combined_df_zt['ZT'] >= 0) & (combined_df_zt['ZT'] < 12)]\n",
    "dark_data = combined_df_zt[(combined_df_zt['ZT'] >= 12) | (combined_df_zt['ZT'] < 0)]  # Assuming ZT=24 wraps around to ZT=0\n",
    "\n",
    "# Calculate average exponent for each subject during light and dark periods\n",
    "avg_exp_light = light_data.groupby('subject')['avg_exps'].mean()\n",
    "avg_exp_dark = dark_data.groupby('subject')['avg_exps'].mean()\n",
    "\n",
    "# Calculate mean and standard error for light and dark periods\n",
    "mean_light = avg_exp_light.mean()\n",
    "mean_dark = avg_exp_dark.mean()\n",
    "sem_light = avg_exp_light.sem()\n",
    "sem_dark = avg_exp_dark.sem()\n",
    "\n",
    "# Calculate average exponent for each day in light and dark periods\n",
    "light_avg_exps = light_data.groupby(light_data['Timestamp'].dt.date)['avg_exps'].mean()\n",
    "dark_avg_exps = dark_data.groupby(dark_data['Timestamp'].dt.date)['avg_exps'].mean()\n",
    "\n",
    "# Create DataFrame for swarmplot\n",
    "data = pd.concat([light_avg_exps, dark_avg_exps], axis=0).reset_index(name='avg_exps')\n",
    "data['Period'] = ['Light']*len(light_avg_exps) + ['Dark']*len(dark_avg_exps)\n",
    "\n",
    "print(f\"Light period: mean = {mean_light:.4f}, SEM = {sem_light:.4f}\")\n",
    "print(f\"Dark period: mean = {mean_dark:.4f}, SEM = {sem_dark:.4f}\")\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = stats.ttest_ind(avg_exp_light, avg_exp_dark)\n",
    "\n",
    "print(f\"\\nt-test results: t = {t_stat:.4f}, p = {p_value:.4f}\")\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style='white')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.errorbar(['Light', 'Dark'], [mean_light, mean_dark], yerr=[sem_light, sem_dark], \n",
    "             capsize=5, marker='o', color='black', linestyle='-', \n",
    "             markerfacecolor='lightskyblue', markeredgecolor='black')\n",
    "sns.swarmplot(x='Period', y='avg_exps', data=data, palette=['orange', 'gray'], alpha=0.3)\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.xlabel('')\n",
    "plt.title('1/f Exponent Across Light and Dark Periods (plotting each day)')\n",
    "plt.xlim(-0.2, 1.2)  # Reduce x-axis limits\n",
    "plt.tight_layout()\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.gcf().set_size_inches(4, 4)  # Reduce figure size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style\n",
    "sns.set(style='white')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.errorbar(['Light', 'Dark'], [mean_light, mean_dark], \n",
    "             capsize=5, marker='x', color='black', linestyle='None',\n",
    "             markerfacecolor='lightskyblue', markeredgecolor='black')\n",
    "\n",
    "# Plot connected dots for each subject\n",
    "for i, (light_val, dark_val) in enumerate(zip(avg_exp_light.values, avg_exp_dark.values)):\n",
    "    plt.plot(['Light', 'Dark'], [light_val, dark_val], color='black', alpha=0.5)\n",
    "    plt.scatter('Light', light_val, color='orange', alpha=0.3)\n",
    "    plt.scatter('Dark', dark_val, color='gray', alpha=0.3)\n",
    "\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.xlabel('')\n",
    "plt.title('1/f Exponent Across Light and Dark Periods (plotting each subject)')\n",
    "plt.xlim(-0.2, 1.2)  # Reduce x-axis limits\n",
    "plt.tight_layout()\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.gcf().set_size_inches(4, 4)  # Reduce figure size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the change in exponent value across light and dark period when pooling all periods\n",
    "\n",
    "# Define quartiles based on ZT\n",
    "light_data['quartile'] = pd.cut(light_data['ZT'], bins=[0, 3, 6, 9, 12], \n",
    "                                labels=['Q1 (0-3)', 'Q2 (3-6)', 'Q3 (6-9)', 'Q4 (9-12)'], \n",
    "                                include_lowest=True)\n",
    "dark_data['quartile'] = pd.cut(dark_data['ZT'], bins=[12, 15, 18, 21, 24], \n",
    "                               labels=['Q1 (12-15)', 'Q2 (15-18)', 'Q3 (18-21)', 'Q4 (21-24)'], \n",
    "                               include_lowest=True)\n",
    "\n",
    "# Calculate average avg_exps in each quartile for each subject\n",
    "light_avg_exps_quartiles = light_data.groupby(['subject', 'quartile'])['avg_exps'].mean()\n",
    "dark_avg_exps_quartiles = dark_data.groupby(['subject', 'quartile'])['avg_exps'].mean()\n",
    "\n",
    "# Reset index to prepare data for AnovaRM\n",
    "light_rm_data = light_avg_exps_quartiles.reset_index()\n",
    "dark_rm_data = dark_avg_exps_quartiles.reset_index()\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "\n",
    "light_anova_rm = AnovaRM(data=light_rm_data, depvar='avg_exps', subject='subject', within=['quartile']).fit()\n",
    "dark_anova_rm = AnovaRM(data=dark_rm_data, depvar='avg_exps', subject='subject', within=['quartile']).fit()\n",
    "\n",
    "print(\"\\nRepeated Measures ANOVA Results for light period:\")\n",
    "print(light_anova_rm.anova_table)\n",
    "print(\"\\nRepeated Measures ANOVA Results for dark period:\")\n",
    "print(dark_anova_rm.anova_table)\n",
    "\n",
    "# Check for significant ANOVA and run post hoc pairwise comparisons\n",
    "light_pairwise, dark_pairwise = None, None\n",
    "\n",
    "if light_anova_rm.anova_table['Pr > F'][0] < 0.05:\n",
    "    print(\"\\nSignificant differences found in light period. Running pairwise comparisons...\")\n",
    "    light_pairwise = pg.pairwise_tests(\n",
    "        data=light_rm_data,\n",
    "        dv='avg_exps',\n",
    "        within='quartile',\n",
    "        subject='subject',\n",
    "        padjust='bonf'\n",
    "    )\n",
    "    print(light_pairwise)\n",
    "\n",
    "if dark_anova_rm.anova_table['Pr > F'][0] < 0.05:\n",
    "    print(\"\\nSignificant differences found in dark period. Running pairwise comparisons...\")\n",
    "    dark_pairwise = pg.pairwise_tests(\n",
    "        data=dark_rm_data,\n",
    "        dv='avg_exps',\n",
    "        within='quartile',\n",
    "        subject='subject',\n",
    "        padjust='bonf'\n",
    "    )\n",
    "    print(dark_pairwise)\n",
    "\n",
    "# Plot the data\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Light Period Plot\n",
    "sns.lineplot(x='quartile', y='avg_exps', hue='subject', data=light_rm_data, alpha=0.3, ax=ax[0])\n",
    "mean_light = light_rm_data.groupby('quartile')['avg_exps'].mean()\n",
    "sem_light = light_rm_data.groupby('quartile')['avg_exps'].sem()\n",
    "ax[0].errorbar(mean_light.index, mean_light, yerr=sem_light, fmt='o-', color='orange', capsize=5, linewidth=2.5)\n",
    "\n",
    "# Annotate significant comparisons for light period\n",
    "if light_pairwise is not None:\n",
    "    for _, row in light_pairwise.iterrows():\n",
    "        if row['p-corr'] < 0.05:\n",
    "            ax[0].text(\n",
    "                x=(int(row['A'][1]) + int(row['B'][1])) / 2 - 1,\n",
    "                y=mean_light.max() + 0.03,\n",
    "                s='*',\n",
    "                ha='center',\n",
    "                fontsize=12,\n",
    "                color='red'\n",
    "            )\n",
    "\n",
    "ax[0].set_xlabel('Zeitgeber Quartile')\n",
    "ax[0].set_ylabel('Exponent Value (a.u.)')\n",
    "ax[0].set_title('1/f Exponent Across Quartiles - Light Period')\n",
    "ax[0].set_ylim([1.05, 1.55])\n",
    "\n",
    "# Dark Period Plot\n",
    "sns.lineplot(x='quartile', y='avg_exps', hue='subject', data=dark_rm_data, alpha=0.3, ax=ax[1])\n",
    "mean_dark = dark_rm_data.groupby('quartile')['avg_exps'].mean()\n",
    "sem_dark = dark_rm_data.groupby('quartile')['avg_exps'].sem()\n",
    "ax[1].errorbar(mean_dark.index, mean_dark, yerr=sem_dark, fmt='o-', color='gray', capsize=5, linewidth=2.5)\n",
    "\n",
    "# Annotate significant comparisons for dark period\n",
    "if dark_pairwise is not None:\n",
    "    for _, row in dark_pairwise.iterrows():\n",
    "        if row['p-corr'] < 0.05:\n",
    "            ax[1].text(\n",
    "                x=(int(row['A'][1]) + int(row['B'][1])) / 2 - 1,\n",
    "                y=mean_dark.max() + 0.03,\n",
    "                s='*',\n",
    "                ha='center',\n",
    "                fontsize=12,\n",
    "                color='red'\n",
    "            )\n",
    "\n",
    "ax[1].set_xlabel('Zeitgeber Quartile')\n",
    "ax[1].set_ylabel('Exponent Value (a.u.)')\n",
    "ax[1].set_title('1/f Exponent Across Quartiles - Dark Period')\n",
    "ax[1].set_ylim([1.05, 1.55])\n",
    "\n",
    "# Remove top and right spines for both subplots\n",
    "for a in ax:\n",
    "    a.spines['top'].set_visible(False)\n",
    "    a.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define quartiles for the light period based on ZT\n",
    "light_data['quartile'] = pd.cut(light_data['ZT'], bins=[0, 3, 6, 9, 12], \n",
    "                                labels=['Q1 (0-3)', 'Q2 (3-6)', 'Q3 (6-9)', 'Q4 (9-12)'], \n",
    "                                include_lowest=True)\n",
    "\n",
    "# Separate light data into different sleep stages\n",
    "light_wake = light_data[light_data['sleepStage'] == 1]\n",
    "light_nrem = light_data[light_data['sleepStage'] == 2]\n",
    "light_rem = light_data[light_data['sleepStage'] == 3]\n",
    "\n",
    "# Function to prepare data for each sleep stage\n",
    "def prepare_stage_data(stage_data):\n",
    "    avg_exps_quartiles = stage_data.groupby(['subject', 'quartile'])['avg_exps'].mean()\n",
    "    return avg_exps_quartiles.reset_index()\n",
    "\n",
    "light_wake_data = prepare_stage_data(light_wake)\n",
    "light_nrem_data = prepare_stage_data(light_nrem)\n",
    "light_rem_data = prepare_stage_data(light_rem)\n",
    "\n",
    "# Function to run repeated measures ANOVA and post-hoc tests\n",
    "def run_anova_and_posthoc(stage_data, stage_name):\n",
    "    # Perform repeated measures ANOVA\n",
    "    aov = pg.rm_anova(dv='avg_exps', within='quartile', subject='subject', data=stage_data, detailed=True)\n",
    "    \n",
    "    print(f\"\\nRepeated Measures ANOVA Results for {stage_name}:\")\n",
    "    print(aov)\n",
    "    \n",
    "    posthoc_results = None\n",
    "    if aov['p-unc'][0] < 0.05:\n",
    "        print(f\"\\nPost-hoc pairwise comparisons for {stage_name}:\")\n",
    "        posthoc_results = pg.pairwise_ttests(dv='avg_exps', within='quartile', subject='subject', data=stage_data, padjust='bonferroni')\n",
    "        print(posthoc_results)\n",
    "    \n",
    "    return aov, posthoc_results\n",
    "\n",
    "# Run ANOVA and post-hoc tests\n",
    "wake_anova, wake_posthoc = run_anova_and_posthoc(light_wake_data, 'Wake')\n",
    "nrem_anova, nrem_posthoc = run_anova_and_posthoc(light_nrem_data, 'NREM')\n",
    "rem_anova, rem_posthoc = run_anova_and_posthoc(light_rem_data, 'REM')\n",
    "\n",
    "# Plot settings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Function to plot stage data with significance annotations\n",
    "def plot_stage_data(data, ax, title, color, posthoc_results):\n",
    "    sns.lineplot(x='quartile', y='avg_exps', hue='subject', data=data, alpha=0.3, ax=ax, palette='Set1')\n",
    "    mean_data = data.groupby('quartile')['avg_exps'].mean()\n",
    "    sem_data = data.groupby('quartile')['avg_exps'].sem()\n",
    "    ax.errorbar(mean_data.index, mean_data, yerr=sem_data, fmt='o-', color=color, capsize=5, linewidth=2.5, label='Mean')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Zeitgeber Quartile')\n",
    "    ax.set_ylabel('Exponent Value (a.u.)')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add significance markers if posthoc results exist\n",
    "    if posthoc_results is not None:\n",
    "        # To track the y_max and avoid overlap of significance lines\n",
    "        max_y = data['avg_exps'].max() + 0.05\n",
    "        for _, row in posthoc_results.iterrows():\n",
    "            if row['p-corr'] < 0.05:\n",
    "                # Use the categorical quartile labels directly from post-hoc test\n",
    "                quartile_1 = row['A']\n",
    "                quartile_2 = row['B']\n",
    "                \n",
    "                # Use the index positions of the quartile labels for plotting\n",
    "                quartile_1_idx = data[data['quartile'] == quartile_1].iloc[0].name\n",
    "                quartile_2_idx = data[data['quartile'] == quartile_2].iloc[0].name\n",
    "\n",
    "                # Define some vertical offset for the significance lines\n",
    "                y_offset = 0.1  # Adjust the vertical distance between significance lines\n",
    "                \n",
    "                # Plot the significance line at y_max for the first quartile pair\n",
    "                ax.plot([quartile_1_idx, quartile_2_idx], [max_y, max_y], color='black', linewidth=1.5)\n",
    "                ax.text((quartile_1_idx + quartile_2_idx) / 2, max_y + 0.0005, '*', ha='center', va='bottom', color='black', fontsize=20)\n",
    "\n",
    "                # Update max_y to be higher for the next significance line\n",
    "                max_y += y_offset\n",
    "\n",
    "# Plot for Wake\n",
    "plot_stage_data(light_wake_data, axes[0], 'Wake - Light Phase', color='blue', posthoc_results=wake_posthoc)\n",
    "\n",
    "# Plot for NREM\n",
    "plot_stage_data(light_nrem_data, axes[1], 'NREM - Light Phase', color='green', posthoc_results=nrem_posthoc)\n",
    "\n",
    "# Plot for REM\n",
    "plot_stage_data(light_rem_data, axes[2], 'REM - Light Phase', color='red', posthoc_results=rem_posthoc)\n",
    "\n",
    "# Remove top and right spines for all plots\n",
    "for ax in axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the change in exponent value across different stage quartiles during dark phase\n",
    "\n",
    "# Define quartiles for the dark period based on ZT\n",
    "dark_data['quartile'] = pd.cut(dark_data['ZT'], bins=[12, 15, 18, 21, 24], \n",
    "                               labels=['Q1 (12-15)', 'Q2 (15-18)', 'Q3 (18-21)', 'Q4 (21-24)'], \n",
    "                               include_lowest=True)\n",
    "\n",
    "# Separate dark data into different sleep stages\n",
    "dark_wake = dark_data[dark_data['sleepStage'] == 1]\n",
    "dark_nrem = dark_data[dark_data['sleepStage'] == 2]\n",
    "dark_rem = dark_data[dark_data['sleepStage'] == 3]\n",
    "\n",
    "# Function to prepare data for each sleep stage\n",
    "def prepare_stage_data(stage_data):\n",
    "    avg_exps_quartiles = stage_data.groupby(['subject', 'quartile'])['avg_exps'].mean()\n",
    "    return avg_exps_quartiles.reset_index()\n",
    "\n",
    "dark_wake_data = prepare_stage_data(dark_wake)\n",
    "dark_nrem_data = prepare_stage_data(dark_nrem)\n",
    "dark_rem_data = prepare_stage_data(dark_rem)\n",
    "\n",
    "# Function to run repeated measures ANOVA and post-hoc tests\n",
    "def run_anova_and_posthoc(stage_data, stage_name):\n",
    "    # Perform repeated measures ANOVA\n",
    "    aov = pg.rm_anova(dv='avg_exps', within='quartile', subject='subject', data=stage_data, detailed=True)\n",
    "    \n",
    "    print(f\"\\nRepeated Measures ANOVA Results for {stage_name}:\")\n",
    "    print(aov)\n",
    "    \n",
    "    posthoc_results = None\n",
    "    if aov['p-unc'][0] < 0.05:\n",
    "        print(f\"\\nPost-hoc pairwise comparisons for {stage_name}:\")\n",
    "        posthoc_results = pg.pairwise_ttests(dv='avg_exps', within='quartile', subject='subject', data=stage_data, padjust='bonferroni')\n",
    "        print(posthoc_results)\n",
    "    \n",
    "    return aov, posthoc_results\n",
    "\n",
    "# Run ANOVA and post-hoc tests for dark period\n",
    "dark_wake_anova, dark_wake_posthoc = run_anova_and_posthoc(dark_wake_data, 'Wake')\n",
    "dark_nrem_anova, dark_nrem_posthoc = run_anova_and_posthoc(dark_nrem_data, 'NREM')\n",
    "dark_rem_anova, dark_rem_posthoc = run_anova_and_posthoc(dark_rem_data, 'REM')\n",
    "\n",
    "# Mapping of quartile labels to numeric values for plotting significance\n",
    "quartile_mapping = {'Q1 (12-15)': 1, 'Q2 (15-18)': 2, 'Q3 (18-21)': 3, 'Q4 (21-24)': 4}\n",
    "\n",
    "# Plot settings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Function to plot stage data with significance annotations\n",
    "def plot_stage_data(data, ax, title, color, posthoc_results):\n",
    "    sns.lineplot(x='quartile', y='avg_exps', hue='subject', data=data, alpha=0.3, ax=ax, palette='Set1')\n",
    "    mean_data = data.groupby('quartile')['avg_exps'].mean()\n",
    "    sem_data = data.groupby('quartile')['avg_exps'].sem()\n",
    "    ax.errorbar(mean_data.index, mean_data, yerr=sem_data, fmt='o-', color=color, capsize=5, linewidth=2.5, label='Mean')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Zeitgeber Quartile')\n",
    "    ax.set_ylabel('Exponent Value (a.u.)')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add significance markers if posthoc results exist\n",
    "    if posthoc_results is not None:\n",
    "        for _, row in posthoc_results.iterrows():\n",
    "            if row['p-corr'] < 0.05:\n",
    "                quartile_1 = quartile_mapping[row['A']]\n",
    "                quartile_2 = quartile_mapping[row['B']]\n",
    "                \n",
    "                y_max = data['avg_exps'].max() + 0.05\n",
    "                # Shift the asterisk downward by increasing the offset\n",
    "                ax.plot([quartile_1, quartile_2], [y_max, y_max], color='black', linewidth=1.5)\n",
    "                # Adjust the position of the asterisk further down\n",
    "                ax.text((quartile_1 + quartile_2) / 2, y_max - 0.05, '*', ha='center', va='bottom', color='black')\n",
    "\n",
    "# Plot for Wake in Dark period\n",
    "plot_stage_data(dark_wake_data, axes[0], 'Wake - Dark Phase', color='blue', posthoc_results=dark_wake_posthoc)\n",
    "\n",
    "# Plot for NREM in Dark period\n",
    "plot_stage_data(dark_nrem_data, axes[1], 'NREM - Dark Phase', color='green', posthoc_results=dark_nrem_posthoc)\n",
    "\n",
    "# Plot for REM in Dark period\n",
    "plot_stage_data(dark_rem_data, axes[2], 'REM - Dark Phase', color='red', posthoc_results=dark_rem_posthoc)\n",
    "\n",
    "# Remove top and right spines for all plots\n",
    "for ax in axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent in first 10 seconds of NREM stage across all phases - run and plot linear regression\n",
    "\n",
    "# Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Find rows immediately after each wake bout\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "next_rows = combined_df_zt.loc[wake_bout_ends + 1]  # Rows immediately after wake bouts\n",
    "\n",
    "# Combine wake bout length with the subsequent avg_exps value\n",
    "wake_bout_analysis = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bouts['wake_bout_length'].values,\n",
    "    'next_avg_exps': next_rows['avg_exps'].values\n",
    "})\n",
    "\n",
    "# Perform linear regression using scipy.stats.linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(wake_bout_analysis['wake_bout_length'], \n",
    "                                                         wake_bout_analysis['next_avg_exps'])\n",
    "\n",
    "# Plot scatterplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=wake_bout_analysis, x='wake_bout_length', y='next_avg_exps', s=50, alpha=0.7)\n",
    "\n",
    "# Plot regression line\n",
    "plt.plot(wake_bout_analysis['wake_bout_length'], intercept + slope * wake_bout_analysis['wake_bout_length'], color='orange')\n",
    "\n",
    "# Add R-squared and p-value to the plot\n",
    "plt.text(0.95, 0.05, f'R² = {r_value**2:.2f}\\nP-value = {p_value:.2f}', \n",
    "         transform=plt.gca().transAxes, fontsize=12, verticalalignment='bottom', horizontalalignment='right',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "# Customize plot appearance\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in First NREM Epoch')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent in first 10 seconds of NREM stage across all phases splitting by light and dark - run and plot linear regression\n",
    "\n",
    "# Function to analyze a given phase (light or dark)\n",
    "def analyze_phase(data, phase_name):\n",
    "    # Create a new column to identify wake bout groups\n",
    "    data['wake_bout'] = (data['sleepStage'] != 1).cumsum()\n",
    "    \n",
    "    # Filter rows where sleepStage is wake (1)\n",
    "    wake_data = data[data['sleepStage'] == 1]\n",
    "    \n",
    "    # Calculate the length of each wake bout\n",
    "    wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "    \n",
    "    # Find rows immediately after each wake bout\n",
    "    wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "    next_indices = wake_bout_ends + 1  # Indices for the next rows\n",
    "    valid_indices = next_indices[next_indices.isin(data.index)]  # Keep only valid indices\n",
    "    \n",
    "    next_rows = data.loc[valid_indices]  # Rows immediately after wake bouts\n",
    "    \n",
    "    # Combine wake bout length with the subsequent avg_exps value\n",
    "    wake_bout_analysis = pd.DataFrame({\n",
    "        'wake_bout_length': wake_bouts['wake_bout_length'].iloc[:len(next_rows)].values,\n",
    "        'next_avg_exps': next_rows['avg_exps'].values\n",
    "    })\n",
    "    \n",
    "    return wake_bout_analysis.dropna()\n",
    "\n",
    "# Analyze light and dark phases\n",
    "light_analysis = analyze_phase(light_data, 'Light')\n",
    "dark_analysis = analyze_phase(dark_data, 'Dark')\n",
    "\n",
    "# Function to perform linear regression and return results\n",
    "def perform_regression(data):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(data['wake_bout_length'], data['next_avg_exps'])\n",
    "    r_squared = r_value**2\n",
    "    return slope, intercept, r_squared, p_value\n",
    "\n",
    "# Perform regression for light and dark phases\n",
    "light_slope, light_intercept, light_r_squared, light_p_value = perform_regression(light_analysis)\n",
    "dark_slope, dark_intercept, dark_r_squared, dark_p_value = perform_regression(dark_analysis)\n",
    "\n",
    "# Predict values for the regression lines\n",
    "light_analysis['predicted'] = light_intercept + light_slope * light_analysis['wake_bout_length']\n",
    "dark_analysis['predicted'] = dark_intercept + dark_slope * dark_analysis['wake_bout_length']\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Light phase subplot\n",
    "sns.scatterplot(data=light_analysis, x='wake_bout_length', y='next_avg_exps', s=50, alpha=0.7, ax=axes[0], color='blue')\n",
    "axes[0].plot(light_analysis['wake_bout_length'], light_analysis['predicted'], color='cyan')\n",
    "\n",
    "# Annotate R² and p-value\n",
    "axes[0].text(0.95, 0.05, f'R² = {light_r_squared:.2f}\\nP-value = {light_p_value:.2f}',\n",
    "             transform=axes[0].transAxes, fontsize=12, verticalalignment='bottom', horizontalalignment='right',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "axes[0].set_title('Wake Bout Length vs. 1/f NREM Exponent (Light Phase)')\n",
    "axes[0].set_xlabel('Wake Bout Length (epochs)')\n",
    "axes[0].set_ylabel('Exponent Value (a.u.)')\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Dark phase subplot\n",
    "sns.scatterplot(data=dark_analysis, x='wake_bout_length', y='next_avg_exps', s=50, alpha=0.7, ax=axes[1], color='orange')\n",
    "axes[1].plot(dark_analysis['wake_bout_length'], dark_analysis['predicted'], color='red')\n",
    "\n",
    "# Annotate R² and p-value\n",
    "axes[1].text(0.95, 0.05, f'R² = {dark_r_squared:.2f}\\nP-value = {dark_p_value:.2f}',\n",
    "             transform=axes[1].transAxes, fontsize=12, verticalalignment='bottom', horizontalalignment='right',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "axes[1].set_title('Wake Bout Length vs. 1/f NREM Exponent (Dark Phase)')\n",
    "axes[1].set_xlabel('Wake Bout Length (epochs)')\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent in first 10 seconds of NREM stage across all phases splitting by light and dark - run and plot linear regression (exclude <=2 bout lengths)\n",
    "\n",
    "# Function to analyze a given phase (light or dark), excluding wake bouts <= 2\n",
    "def analyze_phase(data, phase_name):\n",
    "    # Create a new column to identify wake bout groups\n",
    "    data['wake_bout'] = (data['sleepStage'] != 1).cumsum()\n",
    "    \n",
    "    # Filter rows where sleepStage is wake (1)\n",
    "    wake_data = data[data['sleepStage'] == 1]\n",
    "    \n",
    "    # Calculate the length of each wake bout\n",
    "    wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "    \n",
    "    # Exclude wake bouts with length <= 2\n",
    "    valid_wake_bouts = wake_bouts[wake_bouts['wake_bout_length'] > 2]\n",
    "    valid_wake_data = wake_data[wake_data['wake_bout'].isin(valid_wake_bouts['wake_bout'])]\n",
    "    \n",
    "    # Find rows immediately after each valid wake bout\n",
    "    wake_bout_ends = valid_wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "    next_indices = wake_bout_ends + 1  # Indices for the next rows\n",
    "    valid_indices = next_indices[next_indices.isin(data.index)]  # Keep only valid indices\n",
    "    \n",
    "    next_rows = data.loc[valid_indices]  # Rows immediately after wake bouts\n",
    "    \n",
    "    # Combine wake bout length with the subsequent avg_exps value\n",
    "    wake_bout_analysis = pd.DataFrame({\n",
    "        'wake_bout_length': valid_wake_bouts['wake_bout_length'].iloc[:len(next_rows)].values,\n",
    "        'next_avg_exps': next_rows['avg_exps'].values\n",
    "    })\n",
    "    \n",
    "    return wake_bout_analysis.dropna()\n",
    "\n",
    "# Analyze light and dark phases\n",
    "light_analysis = analyze_phase(light_data, 'Light')\n",
    "dark_analysis = analyze_phase(dark_data, 'Dark')\n",
    "\n",
    "# Perform regression for light and dark phases\n",
    "light_slope, light_intercept, light_r_squared, light_p_value = perform_regression(light_analysis)\n",
    "dark_slope, dark_intercept, dark_r_squared, dark_p_value = perform_regression(dark_analysis)\n",
    "\n",
    "# Predict values for the regression lines\n",
    "light_analysis['predicted'] = light_intercept + light_slope * light_analysis['wake_bout_length']\n",
    "dark_analysis['predicted'] = dark_intercept + dark_slope * dark_analysis['wake_bout_length']\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Light phase subplot\n",
    "sns.scatterplot(data=light_analysis, x='wake_bout_length', y='next_avg_exps', s=50, alpha=0.7, ax=axes[0], color='blue')\n",
    "axes[0].plot(light_analysis['wake_bout_length'], light_analysis['predicted'], color='cyan')\n",
    "\n",
    "# Annotate R² and p-value\n",
    "axes[0].text(0.95, 0.05, f'R² = {light_r_squared:.2f}\\nP-value = {light_p_value:.2f}',\n",
    "             transform=axes[0].transAxes, fontsize=12, verticalalignment='bottom', horizontalalignment='right',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "axes[0].set_title('Wake Bout Length vs. 1/f NREM Exponent (Light Phase) Excluding <=2 Wake Bouts')\n",
    "axes[0].set_xlabel('Wake Bout Length (epochs)')\n",
    "axes[0].set_ylabel('Exponent Value (a.u.)')\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Dark phase subplot\n",
    "sns.scatterplot(data=dark_analysis, x='wake_bout_length', y='next_avg_exps', s=50, alpha=0.7, ax=axes[1], color='orange')\n",
    "axes[1].plot(dark_analysis['wake_bout_length'], dark_analysis['predicted'], color='red')\n",
    "\n",
    "# Annotate R² and p-value\n",
    "axes[1].text(0.95, 0.05, f'R² = {dark_r_squared:.2f}\\nP-value = {dark_p_value:.2f}',\n",
    "             transform=axes[1].transAxes, fontsize=12, verticalalignment='bottom', horizontalalignment='right',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "axes[1].set_title('Wake Bout Length vs. 1/f NREM Exponent (Dark Phase) Excluding <=2 Wake Bouts')\n",
    "axes[1].set_xlabel('Wake Bout Length (epochs)')\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent across the length of the oroceeding NREM stage across all phases & run linear regression\n",
    "\n",
    "# Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Find rows immediately after each wake bout (the start of the next NREM bout)\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "\n",
    "# Initialize lists to hold analysis data\n",
    "wake_bout_lengths = []\n",
    "avg_exps_after_wake = []\n",
    "\n",
    "# Iterate over each wake bout to find the subsequent NREM bout\n",
    "for end_idx in wake_bout_ends:\n",
    "    # Find the index of the first NREM epoch after the wake bout\n",
    "    start_nrem_idx = end_idx + 1\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    if start_nrem_idx >= len(combined_df_zt):\n",
    "        continue\n",
    "    \n",
    "    # Find the rows where sleepStage == 2 (NREM) after the wake bout\n",
    "    nrem_data = combined_df_zt.loc[start_nrem_idx:]\n",
    "    nrem_data = nrem_data[nrem_data['sleepStage'] == 2]\n",
    "    \n",
    "    # Now we need to capture the whole NREM bout and stop when sleepStage is no longer 2\n",
    "    nrem_bout_data = []\n",
    "    for idx, row in nrem_data.iterrows():\n",
    "        # If the sleepStage stays 2, keep adding the data to the bout\n",
    "        nrem_bout_data.append(row)\n",
    "        # If the next row isn't NREM, we stop the bout\n",
    "        if idx + 1 < len(combined_df_zt) and combined_df_zt.loc[idx + 1, 'sleepStage'] != 2:\n",
    "            break\n",
    "    \n",
    "    # If there was a NREM bout, calculate the average exponent value\n",
    "    if nrem_bout_data:\n",
    "        nrem_bout_df = pd.DataFrame(nrem_bout_data)\n",
    "        avg_exp = nrem_bout_df['avg_exps'].mean()\n",
    "        \n",
    "        # Append the wake bout length and the average exponent for this NREM bout\n",
    "        wake_bout_lengths.append(wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0])\n",
    "        avg_exps_after_wake.append(avg_exp)\n",
    "\n",
    "# Create a DataFrame for the analysis\n",
    "wake_bout_analysis = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake\n",
    "})\n",
    "\n",
    "# Drop rows where avg_exp_after_wake is NaN (e.g., no NREM bout follows the wake bout)\n",
    "wake_bout_analysis = wake_bout_analysis.dropna()\n",
    "\n",
    "# Perform linear regression analysis\n",
    "slope, intercept, r_value, p_value, std_err = linregress(wake_bout_analysis['wake_bout_length'], wake_bout_analysis['avg_exp_after_wake'])\n",
    "\n",
    "# Plot wake bout length vs. avg_exps in the following NREM period\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=wake_bout_analysis, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(wake_bout_analysis['wake_bout_length'], slope * wake_bout_analysis['wake_bout_length'] + intercept, color='orange')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display the linear regression statistics on the plot\n",
    "plt.legend()\n",
    "plt.text(0.95, 0.05, f'R-squared = {r_value**2:.3f}\\nSlope = {slope:.2f}\\nP-value = {p_value:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent across the length of the oroceeding NREM stage across all phases & run linear regression - ignore any bouts which are <= 2\n",
    "\n",
    "# Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Find rows immediately after each wake bout (the start of the next NREM bout)\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "\n",
    "# Initialize lists to hold analysis data\n",
    "wake_bout_lengths = []\n",
    "avg_exps_after_wake = []\n",
    "\n",
    "# Iterate over each wake bout to find the subsequent NREM bout\n",
    "for end_idx in wake_bout_ends:\n",
    "    # Find the index of the first NREM epoch after the wake bout\n",
    "    start_nrem_idx = end_idx + 1\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    if start_nrem_idx >= len(combined_df_zt):\n",
    "        continue\n",
    "    \n",
    "    # Find the rows where sleepStage == 2 (NREM) after the wake bout\n",
    "    nrem_data = combined_df_zt.loc[start_nrem_idx:]\n",
    "    nrem_data = nrem_data[nrem_data['sleepStage'] == 2]\n",
    "    \n",
    "    # Now we need to capture the whole NREM bout and stop when sleepStage is no longer 2\n",
    "    nrem_bout_data = []\n",
    "    for idx, row in nrem_data.iterrows():\n",
    "        # If the sleepStage stays 2, keep adding the data to the bout\n",
    "        nrem_bout_data.append(row)\n",
    "        # If the next row isn't NREM, we stop the bout\n",
    "        if idx + 1 < len(combined_df_zt) and combined_df_zt.loc[idx + 1, 'sleepStage'] != 2:\n",
    "            break\n",
    "    \n",
    "    # If there was a NREM bout, calculate the average exponent value\n",
    "    if nrem_bout_data:\n",
    "        nrem_bout_df = pd.DataFrame(nrem_bout_data)\n",
    "        avg_exp = nrem_bout_df['avg_exps'].mean()\n",
    "        \n",
    "        # Append the wake bout length and the average exponent for this NREM bout\n",
    "        bout_length = wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0]\n",
    "        \n",
    "        # Only append if bout length is greater than 2\n",
    "        if bout_length > 2:\n",
    "            wake_bout_lengths.append(bout_length)\n",
    "            avg_exps_after_wake.append(avg_exp)\n",
    "\n",
    "# Create a DataFrame for the analysis\n",
    "wake_bout_analysis = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake\n",
    "})\n",
    "\n",
    "# Drop rows where avg_exp_after_wake is NaN (e.g., no NREM bout follows the wake bout)\n",
    "wake_bout_analysis = wake_bout_analysis.dropna()\n",
    "\n",
    "# Perform linear regression analysis\n",
    "if len(wake_bout_analysis) > 1:  # Ensure there is enough data for regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(wake_bout_analysis['wake_bout_length'], wake_bout_analysis['avg_exp_after_wake'])\n",
    "\n",
    "    # Plot wake bout length vs. avg_exps in the following NREM period\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=wake_bout_analysis, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "\n",
    "    # Plot the regression line\n",
    "    plt.plot(wake_bout_analysis['wake_bout_length'], slope * wake_bout_analysis['wake_bout_length'] + intercept, color='orange')\n",
    "\n",
    "    # Remove top and right spines\n",
    "    ax = plt.gca()  \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.xlabel('Wake Bout Length (epochs)')\n",
    "    plt.ylabel('Exponent Value (a.u.)')\n",
    "    plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch (exclude <=2 bout length)')\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Display the linear regression statistics on the plot\n",
    "    plt.legend()\n",
    "    plt.text(0.95, 0.05, f'R-squared = {r_value**2:.3f}\\nSlope = {slope:.2f}\\nP-value = {p_value:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data for linear regression analysis after filtering out short wake bouts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot length of time awake vs exponent across the length of the oroceeding NREM stage across split across light and dark phase & run linear regression\n",
    "\n",
    "# Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Find rows immediately after each wake bout (the start of the next NREM bout)\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "\n",
    "# Initialize lists to hold analysis data\n",
    "wake_bout_lengths_light = []\n",
    "avg_exps_after_wake_light = []\n",
    "wake_bout_lengths_dark = []\n",
    "avg_exps_after_wake_dark = []\n",
    "\n",
    "# Iterate over each wake bout to find the subsequent NREM bout\n",
    "for end_idx in wake_bout_ends:\n",
    "    # Find the index of the first NREM epoch after the wake bout\n",
    "    start_nrem_idx = end_idx + 1\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    if start_nrem_idx >= len(combined_df_zt):\n",
    "        continue\n",
    "    \n",
    "    # Find the rows where sleepStage == 2 (NREM) after the wake bout\n",
    "    nrem_data = combined_df_zt.loc[start_nrem_idx:]\n",
    "    nrem_data = nrem_data[nrem_data['sleepStage'] == 2]\n",
    "    \n",
    "    # Now we need to capture the whole NREM bout and stop when sleepStage is no longer 2\n",
    "    nrem_bout_data = []\n",
    "    for idx, row in nrem_data.iterrows():\n",
    "        # If the sleepStage stays 2, keep adding the data to the bout\n",
    "        nrem_bout_data.append(row)\n",
    "        # If the next row isn't NREM, we stop the bout\n",
    "        if idx + 1 < len(combined_df_zt) and combined_df_zt.loc[idx + 1, 'sleepStage'] != 2:\n",
    "            break\n",
    "    \n",
    "    # If there was a NREM bout, calculate the average exponent value\n",
    "    if nrem_bout_data:\n",
    "        nrem_bout_df = pd.DataFrame(nrem_bout_data)\n",
    "        avg_exp = nrem_bout_df['avg_exps'].mean()\n",
    "        \n",
    "        # Determine whether it's light or dark phase\n",
    "        zt = combined_df_zt.loc[end_idx, 'ZT']\n",
    "        if 0 <= zt < 12:  # Light phase\n",
    "            wake_bout_lengths_light.append(wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0])\n",
    "            avg_exps_after_wake_light.append(avg_exp)\n",
    "        else:  # Dark phase\n",
    "            wake_bout_lengths_dark.append(wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0])\n",
    "            avg_exps_after_wake_dark.append(avg_exp)\n",
    "\n",
    "# Create DataFrames for the analysis\n",
    "wake_bout_analysis_light = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths_light,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake_light\n",
    "})\n",
    "\n",
    "wake_bout_analysis_dark = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths_dark,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake_dark\n",
    "})\n",
    "\n",
    "# Drop rows where avg_exp_after_wake is NaN (e.g., no NREM bout follows the wake bout)\n",
    "wake_bout_analysis_light = wake_bout_analysis_light.dropna()\n",
    "wake_bout_analysis_dark = wake_bout_analysis_dark.dropna()\n",
    "\n",
    "# Perform linear regression analysis\n",
    "slope_light, intercept_light, r_value_light, p_value_light, std_err_light = linregress(wake_bout_analysis_light['wake_bout_length'], wake_bout_analysis_light['avg_exp_after_wake'])\n",
    "slope_dark, intercept_dark, r_value_dark, p_value_dark, std_err_dark = linregress(wake_bout_analysis_dark['wake_bout_length'], wake_bout_analysis_dark['avg_exp_after_wake'])\n",
    "\n",
    "# Plot wake bout length vs. avg_exps in the following NREM period for light and dark phases\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(data=wake_bout_analysis_light, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "plt.plot(wake_bout_analysis_light['wake_bout_length'], slope_light * wake_bout_analysis_light['wake_bout_length'] + intercept_light, color='orange')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch (Light)')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display the linear regression statistics on the plot\n",
    "plt.legend()\n",
    "plt.text(0.95, 0.05, f'R-squared = {r_value_light**2:.3f}\\nSlope = {slope_light:.2f}\\nP-value = {p_value_light:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=wake_bout_analysis_dark, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "plt.plot(wake_bout_analysis_dark['wake_bout_length'], slope_dark * wake_bout_analysis_dark['wake_bout_length'] + intercept_dark, color='orange')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch (Dark)')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display the linear regression statistics on the plot\n",
    "plt.legend()\n",
    "plt.text(0.95, 0.05, f'R-squared = {r_value_dark**2:.3f}\\nSlope = {slope_dark:.2f}\\nP-value = {p_value_dark:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Filter out wake bouts with length <= 2\n",
    "wake_bouts = wake_bouts[wake_bouts['wake_bout_length'] > 2]\n",
    "\n",
    "# Find rows immediately after each wake bout (the start of the next NREM bout)\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "\n",
    "# Initialize lists to hold analysis data\n",
    "wake_bout_lengths_light = []\n",
    "avg_exps_after_wake_light = []\n",
    "wake_bout_lengths_dark = []\n",
    "avg_exps_after_wake_dark = []\n",
    "\n",
    "# Iterate over each wake bout to find the subsequent NREM bout\n",
    "for end_idx in wake_bout_ends:\n",
    "    # Check if the wake bout length is > 2\n",
    "    wake_bout_filter = wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout']]\n",
    "    if wake_bout_filter.empty or wake_bout_filter['wake_bout_length'].values[0] <= 2:\n",
    "        continue\n",
    "    \n",
    "    # Find the index of the first NREM epoch after the wake bout\n",
    "    start_nrem_idx = end_idx + 1\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    if start_nrem_idx >= len(combined_df_zt):\n",
    "        continue\n",
    "    \n",
    "    # Find the rows where sleepStage == 2 (NREM) after the wake bout\n",
    "    nrem_data = combined_df_zt.loc[start_nrem_idx:]\n",
    "    nrem_data = nrem_data[nrem_data['sleepStage'] == 2]\n",
    "    \n",
    "    # Now we need to capture the whole NREM bout and stop when sleepStage is no longer 2\n",
    "    nrem_bout_data = []\n",
    "    for idx, row in nrem_data.iterrows():\n",
    "        # If the sleepStage stays 2, keep adding the data to the bout\n",
    "        nrem_bout_data.append(row)\n",
    "        # If the next row isn't NREM, we stop the bout\n",
    "        if idx + 1 < len(combined_df_zt) and combined_df_zt.loc[idx + 1, 'sleepStage'] != 2:\n",
    "            break\n",
    "    \n",
    "    # If there was a NREM bout, calculate the average exponent value\n",
    "    if nrem_bout_data:\n",
    "        nrem_bout_df = pd.DataFrame(nrem_bout_data)\n",
    "        avg_exp = nrem_bout_df['avg_exps'].mean()\n",
    "        \n",
    "        # Determine whether it's light or dark phase\n",
    "        zt = combined_df_zt.loc[end_idx, 'ZT']\n",
    "        if 0 <= zt < 12:  # Light phase\n",
    "            wake_bout_lengths_light.append(wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0])\n",
    "            avg_exps_after_wake_light.append(avg_exp)\n",
    "        else:  # Dark phase\n",
    "            wake_bout_lengths_dark.append(wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0])\n",
    "            avg_exps_after_wake_dark.append(avg_exp)\n",
    "\n",
    "# Create DataFrames for the analysis\n",
    "wake_bout_analysis_light = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths_light,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake_light\n",
    "})\n",
    "\n",
    "wake_bout_analysis_dark = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths_dark,\n",
    "    'avg_exp_after_wake': avg_exps_after_wake_dark\n",
    "})\n",
    "\n",
    "# Drop rows where avg_exp_after_wake is NaN (e.g., no NREM bout follows the wake bout)\n",
    "wake_bout_analysis_light = wake_bout_analysis_light.dropna()\n",
    "wake_bout_analysis_dark = wake_bout_analysis_dark.dropna()\n",
    "\n",
    "# Perform linear regression analysis\n",
    "slope_light, intercept_light, r_value_light, p_value_light, std_err_light = linregress(wake_bout_analysis_light['wake_bout_length'], wake_bout_analysis_light['avg_exp_after_wake'])\n",
    "slope_dark, intercept_dark, r_value_dark, p_value_dark, std_err_dark = linregress(wake_bout_analysis_dark['wake_bout_length'], wake_bout_analysis_dark['avg_exp_after_wake'])\n",
    "\n",
    "# Plot wake bout length vs. avg_exps in the following NREM period for light and dark phases\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(data=wake_bout_analysis_light, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "plt.plot(wake_bout_analysis_light['wake_bout_length'], slope_light * wake_bout_analysis_light['wake_bout_length'] + intercept_light, color='orange')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch (Light) exclude <=2 wake bout')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display the linear regression statistics on the plot\n",
    "plt.legend()\n",
    "plt.text(0.95, 0.05, f'R-squared = {r_value_light**2:.3f}\\nSlope = {slope_light:.2f}\\nP-value = {p_value_light:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=wake_bout_analysis_dark, x='wake_bout_length', y='avg_exp_after_wake', s=50, alpha=0.7)\n",
    "plt.plot(wake_bout_analysis_dark['wake_bout_length'], slope_dark * wake_bout_analysis_dark['wake_bout_length'] + intercept_dark, color='orange')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax = plt.gca()  \n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Wake Bout Length (epochs)')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs. 1/f Exponent in NREM Epoch (Dark) exclude <=2 wake bout')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display the linear regression statistics on the plot\n",
    "plt.legend()\n",
    "plt.text(0.95, 0.05, f'R-squared = {r_value_dark**2:.3f}\\nSlope = {slope_dark:.2f}\\nP-value = {p_value_dark:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "# Adjust layout to increase horizontal spacing between plots\n",
    "plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out wake_bout_length < 3\n",
    "wake_data_filtered = wake_data[wake_data['wake_bout_length'] >= 3]\n",
    "\n",
    "# Function to split bout into tertiles and distribute length appropriately\n",
    "def split_into_tertiles(wake_bout_length):\n",
    "    base_size = wake_bout_length // 3\n",
    "    remainder = wake_bout_length % 3\n",
    "    tertiles = [base_size + (1 if i < remainder else 0) for i in range(3)]\n",
    "    return tertiles\n",
    "\n",
    "# Function to assign tertiles within each bout_group\n",
    "def assign_tertiles(group):\n",
    "    tertiles = split_into_tertiles(group['wake_bout_length'].iloc[0])\n",
    "    group['tert_group'] = np.concatenate([\n",
    "        np.repeat(i + 1, tertiles[i]) for i in range(3)\n",
    "    ])\n",
    "    return group\n",
    "\n",
    "# Apply tertile assignment within each bout_group\n",
    "wake_data_filtered = wake_data_filtered.groupby('bout_group').apply(assign_tertiles)\n",
    "\n",
    "# Calculate the average of avg_exps in each tertile\n",
    "tertile_avg_exps = wake_data_filtered.groupby(['subject', 'tert_group'])['avg_exps'].mean().reset_index()\n",
    "\n",
    "# Perform repeated measures ANOVA using Pingouin\n",
    "anova_results = pg.rm_anova(dv='avg_exps', within='tert_group', subject='subject', data=tertile_avg_exps, detailed=True)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(anova_results)\n",
    "\n",
    "# Check if the p-value is significant (less than 0.05)\n",
    "p_value = anova_results['p-unc'][0]\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a scatterplot for individual subjects\n",
    "sns.scatterplot(data=tertile_avg_exps, x='tert_group', y='avg_exps', hue='subject', palette='Set1', legend=None, alpha=0.5, s=80)\n",
    "\n",
    "# Plot the average across all subjects with error bars\n",
    "sns.lineplot(data=tert_group_means, x='tert_group', y='avg_exps', color='black', lw=2)\n",
    "\n",
    "# Calculate the means and standard errors for each tertile\n",
    "tert_group_means = tertile_avg_exps.groupby('tert_group')['avg_exps'].mean().reset_index()\n",
    "tert_group_sems = tertile_avg_exps.groupby('tert_group')['avg_exps'].sem().reset_index()\n",
    "\n",
    "# Plot error bars (mean ± SEM) for each tertile\n",
    "plt.errorbar(tert_group_means['tert_group'], tert_group_means['avg_exps'], \n",
    "             yerr=tert_group_sems['avg_exps'], fmt='none', color='black', lw=2, capsize=5)\n",
    "\n",
    "\n",
    "# If the p-value is significant, perform post-hoc pairwise comparisons\n",
    "if p_value < 0.05:\n",
    "    print(\"Significant difference found, performing post-hoc pairwise comparisons...\")\n",
    "    \n",
    "    # Perform post-hoc pairwise comparisons using Bonferroni correction\n",
    "    post_hoc_results = pg.pairwise_ttests(dv='avg_exps', within='tert_group', subject='subject', data=tertile_avg_exps, padjust='bonf')\n",
    "    \n",
    "    # Print the results of the pairwise comparisons\n",
    "    print(post_hoc_results)\n",
    "    \n",
    "    # Extract significant comparisons\n",
    "    significant_comparisons = post_hoc_results[post_hoc_results['p-corrected'] < 0.05]\n",
    "    \n",
    "    # Plot significant pairwise comparisons with asterisks\n",
    "    for _, row in significant_comparisons.iterrows():\n",
    "        x1, x2 = row['A'], row['B']\n",
    "        y = tertile_avg_exps['avg_exps'].max() + 0.05  # Adding a small offset for visibility\n",
    "        plt.plot([x1, x2], [y, y], color='black', lw=1)\n",
    "        plt.text((x1 + x2) / 2, y, '*', ha='center', va='bottom', color='black', fontsize=12)\n",
    "\n",
    "else:\n",
    "    print(\"No significant difference found.\")\n",
    "\n",
    "# Display grid and remove top/right spines for cleaner look\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('1/f Exponent Across Tertiles of Wake Bouts')\n",
    "plt.xlabel('Tertile of Wake Bout')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.xticks([1, 2, 3], labels=['1', '2', '3'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## During wake split each bout into tertiles and determine whether there is a change in the exponent value across the tertile - filter out bouts which have less than 3 length (create boxplots)\n",
    "\n",
    "# Filter out wake_bout_length < 3\n",
    "wake_data_filtered = wake_data[wake_data['wake_bout_length'] >= 3]\n",
    "\n",
    "# Function to split bout into tertiles and distribute length appropriately\n",
    "def split_into_tertiles(wake_bout_length):\n",
    "    # Calculate the base size of each tertile\n",
    "    base_size = wake_bout_length // 3\n",
    "    remainder = wake_bout_length % 3\n",
    "    \n",
    "    # Distribute the remainder evenly across the tertiles\n",
    "    tertiles = [base_size + (1 if i < remainder else 0) for i in range(3)]\n",
    "    \n",
    "    return tertiles\n",
    "\n",
    "# Add a 'tert_group' column to indicate tertile number for each row in the bout\n",
    "def assign_tertiles(group):\n",
    "    tertiles = split_into_tertiles(group['wake_bout_length'].iloc[0])\n",
    "    tert_start_idx = 0\n",
    "    group['tert_group'] = np.concatenate([\n",
    "        np.repeat(i + 1, tertiles[i]) for i in range(3)\n",
    "    ])\n",
    "    return group\n",
    "\n",
    "# Apply tertile assignment within each bout_group\n",
    "wake_data_filtered = wake_data_filtered.groupby('bout_group').apply(assign_tertiles)\n",
    "\n",
    "# Now, we can directly plot all avg_exps for each subject in each tertile\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a boxplot for each tertile\n",
    "sns.boxplot(data=wake_data_filtered, x='tert_group', y='avg_exps', hue='tert_group', palette='Set1', \n",
    "            showmeans=True, meanline=True, linewidth=2)\n",
    "\n",
    "# Calculate the average across all subjects for each tertile\n",
    "tert_group_means = wake_data_filtered.groupby('tert_group')['avg_exps'].mean().reset_index()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Tertile of Wake Bout')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('1/f Exponent Across Tertiles of Wake Bouts')\n",
    "\n",
    "# Customize legend\n",
    "plt.legend('')\n",
    "\n",
    "# Display grid and remove top/right spines for cleaner look\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation of length of wake with its corresponding last tertile value in the same bout - exclude bouts <3 length\n",
    "\n",
    "# Filter for tert_group = 3\n",
    "tert_group_3 = wake_data_filtered[wake_data_filtered['tert_group'] == 3]\n",
    "\n",
    "# Reset index to remove ambiguity between index and column labels\n",
    "tert_group_3 = tert_group_3.reset_index(drop=True)\n",
    "\n",
    "# Compute mean avg_exps for each bout_group when tert_group = 3\n",
    "tert_group_3_means = tert_group_3.groupby('bout_group')['avg_exps'].mean().reset_index()\n",
    "tert_group_3_means.rename(columns={'avg_exps': 'avg_exps_mean'}, inplace=True)\n",
    "\n",
    "# Extract wake_bout_length for each bout_group\n",
    "bout_lengths = wake_data_filtered[['bout_group', 'wake_bout_length']].drop_duplicates()\n",
    "\n",
    "# Reset index for bout_lengths to avoid conflicts\n",
    "bout_lengths = bout_lengths.reset_index(drop=True)\n",
    "\n",
    "# Merge the mean avg_exps with bout_lengths\n",
    "correlation_data = pd.merge(tert_group_3_means, bout_lengths, on='bout_group')\n",
    "\n",
    "# Calculate correlation\n",
    "correlation, p_value = stats.pearsonr(correlation_data['wake_bout_length'], correlation_data['avg_exps_mean'])\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=correlation_data, x='wake_bout_length', y='avg_exps_mean', color='blue', s=80, alpha=0.7)\n",
    "\n",
    "# Add regression line\n",
    "sns.regplot(data=correlation_data, x='wake_bout_length', y='avg_exps_mean', scatter=False, color='red', ci=None)\n",
    "\n",
    "# Annotate with correlation results\n",
    "plt.text(x=max(correlation_data['wake_bout_length']) * 0.7, \n",
    "         y=max(correlation_data['avg_exps_mean']) * 0.9,\n",
    "         s=f\"r = {correlation:.3f}\\np = {p_value:.3f}\",\n",
    "         fontsize=12, color='black', bbox=dict(facecolor='white', edgecolor='gray', alpha=0.7))\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Wake Bout Length')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.title('Wake Bout Length vs 1/f Exponent in Tertile 3')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation of length of waking period and the maximum exponent in the subsequent NREM episode - exclude bouts <=2 in length\n",
    "\n",
    "# Step 1: Create a new column to identify wake bout groups\n",
    "combined_df_zt['wake_bout'] = (combined_df_zt['sleepStage'] != 1).cumsum()\n",
    "\n",
    "# Step 2: Filter rows where sleepStage is wake (1)\n",
    "wake_data = combined_df_zt[combined_df_zt['sleepStage'] == 1]\n",
    "\n",
    "# Step 3: Calculate the length of each wake bout\n",
    "wake_bouts = wake_data.groupby('wake_bout').size().reset_index(name='wake_bout_length')\n",
    "\n",
    "# Step 4: Find rows immediately after each wake bout (the start of the next NREM bout)\n",
    "wake_bout_ends = wake_data.groupby('wake_bout').tail(1).index  # Last row of each wake bout\n",
    "\n",
    "# Step 5: Initialize lists to hold analysis data\n",
    "wake_bout_lengths = []\n",
    "max_exps_after_wake = []\n",
    "\n",
    "# Step 6: Iterate over each wake bout to find the subsequent NREM bout\n",
    "for end_idx in wake_bout_ends:\n",
    "    # Find the index of the first NREM epoch after the wake bout\n",
    "    start_nrem_idx = end_idx + 1\n",
    "    \n",
    "    # Ensure we don't go out of bounds\n",
    "    if start_nrem_idx >= len(combined_df_zt):\n",
    "        continue\n",
    "    \n",
    "    # Find the rows where sleepStage == 2 (NREM) after the wake bout\n",
    "    nrem_data = combined_df_zt.loc[start_nrem_idx:]\n",
    "    nrem_data = nrem_data[nrem_data['sleepStage'] == 2]\n",
    "    \n",
    "    # Now we need to capture the whole NREM bout and stop when sleepStage is no longer 2\n",
    "    nrem_bout_data = []\n",
    "    for idx, row in nrem_data.iterrows():\n",
    "        # If the sleepStage stays 2, keep adding the data to the bout\n",
    "        nrem_bout_data.append(row)\n",
    "        # If the next row isn't NREM, we stop the bout\n",
    "        if idx + 1 < len(combined_df_zt) and combined_df_zt.loc[idx + 1, 'sleepStage'] != 2:\n",
    "            break\n",
    "    \n",
    "    # If there was a NREM bout, calculate the maximum exponent value\n",
    "    if nrem_bout_data:\n",
    "        nrem_bout_df = pd.DataFrame(nrem_bout_data)\n",
    "        max_exp = nrem_bout_df['avg_exps'].max()  # Get the maximum exponent value\n",
    "        \n",
    "        # Append the wake bout length and the maximum exponent for this NREM bout\n",
    "        bout_length = wake_bouts.loc[wake_bouts['wake_bout'] == combined_df_zt.loc[end_idx, 'wake_bout'], 'wake_bout_length'].values[0]\n",
    "        \n",
    "        # Only append if bout length is greater than 2\n",
    "        if bout_length > 2:\n",
    "            wake_bout_lengths.append(bout_length)\n",
    "            max_exps_after_wake.append(max_exp)\n",
    "\n",
    "# Step 7: Create a DataFrame for the analysis\n",
    "wake_bout_analysis = pd.DataFrame({\n",
    "    'wake_bout_length': wake_bout_lengths,\n",
    "    'max_exp_after_wake': max_exps_after_wake\n",
    "})\n",
    "\n",
    "# Step 8: Drop rows where max_exp_after_wake is NaN (e.g., no NREM bout follows the wake bout)\n",
    "wake_bout_analysis = wake_bout_analysis.dropna()\n",
    "\n",
    "# Step 9: Perform linear regression analysis\n",
    "if len(wake_bout_analysis) > 1:  # Ensure there is enough data for regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(wake_bout_analysis['wake_bout_length'], wake_bout_analysis['max_exp_after_wake'])\n",
    "\n",
    "    # Plot wake bout length vs. max_exps in the following NREM period\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=wake_bout_analysis, x='wake_bout_length', y='max_exp_after_wake', s=50, alpha=0.7)\n",
    "\n",
    "    # Plot the regression line\n",
    "    plt.plot(wake_bout_analysis['wake_bout_length'], slope * wake_bout_analysis['wake_bout_length'] + intercept, color='orange')\n",
    "\n",
    "    # Remove top and right spines\n",
    "    ax = plt.gca()  \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.xlabel('Wake Bout Length (epochs)')\n",
    "    plt.ylabel('Max Exponent in Subsequent NREM Bout')\n",
    "    plt.title('Wake Bout Length vs. Max Exponent in NREM Epoch (exclude <=2 bout length)')\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Display the linear regression statistics on the plot\n",
    "    plt.legend()\n",
    "    plt.text(0.95, 0.05, f'R-squared = {r_value**2:.3f}\\nSlope = {slope:.2f}\\nP-value = {p_value:.3f}', transform=plt.gca().transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data for linear regression analysis after filtering out short wake bouts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## During non-rem split each bout into tertiles and determine whether there is a change in the exponent value across the tertile - filter out bouts which have less than 3 length\n",
    "\n",
    "# First add non-rem bout info to the combined_df_zt df\n",
    "\n",
    "# Check if 'non_rem_bout_length' column already exists, and drop it if necessary\n",
    "if 'non_rem_bout_length' in combined_df_zt.columns:\n",
    "    combined_df_zt = combined_df_zt.drop(columns=['non_rem_bout_length'])\n",
    "\n",
    "# Create 'non_rem_bout' column for identifying NREM bout group identifiers\n",
    "combined_df_zt['non_rem_bout'] = (combined_df_zt['sleepStage'] != 2).cumsum()\n",
    "\n",
    "# Filter for NREM epochs (sleepStage == 2)\n",
    "nrem_data = combined_df_zt[combined_df_zt['sleepStage'] == 2]\n",
    "\n",
    "# Calculate the length of each NREM bout (group size)\n",
    "nrem_bout_lengths = nrem_data.groupby('non_rem_bout').size().reset_index(name='non_rem_bout_length')\n",
    "\n",
    "# Merge the NREM bout length information and bout group back into combined_df_zt\n",
    "combined_df_zt = combined_df_zt.merge(nrem_bout_lengths[['non_rem_bout', 'non_rem_bout_length']], \n",
    "                                       on='non_rem_bout', how='left')\n",
    "\n",
    "# Filter out for non-rem data once it has been added to the combined_df_zt df\n",
    "nrem_data = combined_df_zt[combined_df_zt['sleepStage'] == 2]\n",
    "\n",
    "# Filter out NREM bouts with non_rem_bout_length < 3\n",
    "nrem_data_filtered = nrem_data[nrem_data['non_rem_bout_length'] >= 3]\n",
    "\n",
    "# Function to split NREM bout into tertiles and distribute length appropriately\n",
    "def split_into_tertiles(nrem_bout_length):\n",
    "    base_size = nrem_bout_length // 3\n",
    "    remainder = nrem_bout_length % 3\n",
    "    tertiles = [base_size + (1 if i < remainder else 0) for i in range(3)]\n",
    "    return tertiles\n",
    "\n",
    "def assign_tertiles(group):\n",
    "    tertiles = split_into_tertiles(group['non_rem_bout_length'].iloc[0])\n",
    "    group = group.copy()  # Avoid modifying the original DataFrame in-place\n",
    "    group['tert_group'] = np.concatenate([\n",
    "        np.repeat(i + 1, tertiles[i]) for i in range(3)\n",
    "    ])\n",
    "    return group\n",
    "\n",
    "# Apply tertile assignment within each non-REM bout group\n",
    "nrem_data_filtered = nrem_data_filtered.groupby('non_rem_bout').apply(assign_tertiles).reset_index(drop=True)\n",
    "\n",
    "# Calculate the average of avg_exps in each tertile for NREM bouts\n",
    "tertile_avg_exps_nrem = nrem_data_filtered.groupby(['subject', 'tert_group'])['avg_exps'].mean().reset_index()\n",
    "\n",
    "# Calculate the average across all subjects for each tertile\n",
    "tert_group_means_nrem = tertile_avg_exps_nrem.groupby('tert_group')['avg_exps'].mean().reset_index()\n",
    "\n",
    "# Calculate standard error of the mean (SEM) for error bars\n",
    "tertile_group_sems_nrem = tertile_avg_exps_nrem.groupby('tert_group')['avg_exps'].sem().reset_index()\n",
    "\n",
    "# Perform repeated measures ANOVA using Pingouin\n",
    "anova_results_nrem = pg.rm_anova(dv='avg_exps', within='tert_group', subject='subject', data=tertile_avg_exps_nrem, detailed=True)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(\"Repeated Measures ANOVA Results:\\n\", anova_results_nrem)\n",
    "\n",
    "# Perform posthoc pairwise t-tests with correction for multiple comparisons\n",
    "posthoc_results = pg.pairwise_ttests(\n",
    "    dv='avg_exps', within='tert_group', subject='subject', \n",
    "    data=tertile_avg_exps_nrem, padjust='bonferroni'\n",
    ")\n",
    "\n",
    "# Print the posthoc test results\n",
    "print(\"\\nPosthoc Pairwise Comparisons (Bonferroni-corrected):\\n\", posthoc_results)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatterplot for individual subjects\n",
    "scatter = sns.scatterplot(\n",
    "    data=tertile_avg_exps_nrem, \n",
    "    x='tert_group', y='avg_exps', \n",
    "    hue='subject', palette='Set1', alpha=0.5, s=100\n",
    ")\n",
    "\n",
    "# Line plot linking the means across tertiles\n",
    "sns.lineplot(\n",
    "    data=tert_group_means_nrem, x='tert_group', y='avg_exps', \n",
    "    color='black', lw=2, label='Mean ± SEM'\n",
    ")\n",
    "\n",
    "# Add mean and SEM error bars\n",
    "plt.errorbar(\n",
    "    x=tert_group_means_nrem['tert_group'], \n",
    "    y=tert_group_means_nrem['avg_exps'], \n",
    "    yerr=tertile_group_sems_nrem['avg_exps'], \n",
    "    fmt='o', color='black', lw=2, capsize=5\n",
    ")\n",
    "\n",
    "# Add significant differences with bars lifted above the plot\n",
    "y_offset = tert_group_means_nrem['avg_exps'].max() + 0.2  # Start higher above the data\n",
    "for i, row in posthoc_results.iterrows():\n",
    "    if row['p-corr'] < 0.05:  # Only annotate significant comparisons\n",
    "        x1, x2 = row['A'], row['B']\n",
    "        y = y_offset + i * 0.05  # Add spacing for multiple bars\n",
    "        plt.plot([x1, x2], [y, y], color='black', lw=1.5)\n",
    "\n",
    "        # Determine significance level and corresponding asterisks\n",
    "        if row['p-corr'] < 0.001:\n",
    "            significance = '***'\n",
    "        elif row['p-corr'] < 0.01:\n",
    "            significance = '**'\n",
    "        elif row['p-corr'] < 0.05:\n",
    "            significance = '*'\n",
    "        else:\n",
    "            significance = ''  # No marker for non-significant results\n",
    "\n",
    "        # Annotate plot\n",
    "        plt.text((x1 + x2) / 2, y + 0.0005, significance, ha='center', va='bottom', \n",
    "                 color='black', fontsize=20)\n",
    "\n",
    "# Adjusting legend to show individual subject colors\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "plt.legend(\n",
    "    handles=handles[:-1], labels=labels[:-1],  # Skip the 'subject' title entry\n",
    "    title='Subjects', loc='upper left', borderaxespad=0\n",
    ")\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.title('1/f Exponent Across Tertiles of NREM Bouts')\n",
    "plt.xlabel('Tertile of NREM Bout')\n",
    "plt.ylabel('Exponent Value (a.u.)')\n",
    "plt.xticks([1, 2, 3], labels=['1', '2', '3'])\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Clean up plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrem_data = nrem_data.drop(columns=['non_rem_bout_length_x', 'non_rem_bout_length_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Does change of exponent across a NREM bout correlate with bout length - does longer bout length correlate with difference between first and last tertile\n",
    "\n",
    "# Step 1: Filter for tert_group=1 and tert_group=3\n",
    "tertile_groups = nrem_data_filtered[nrem_data_filtered['tert_group'].isin([1, 3])]\n",
    "\n",
    "# Step 2: Calculate mean avg_exps for tert_group=1 and tert_group=3 within each bout\n",
    "tertile_means = (\n",
    "    tertile_groups.groupby(['non_rem_bout', 'tert_group'])['avg_exps']\n",
    "    .mean()\n",
    "    .unstack(level='tert_group')\n",
    ")\n",
    "\n",
    "# Ensure both tert_group=1 and tert_group=3 exist for each bout\n",
    "tertile_means = tertile_means.dropna(subset=[1, 3])\n",
    "\n",
    "# Step 3: Compute the difference between tert_group=1 and tert_group=3\n",
    "tertile_means['mean_diff'] = tertile_means[3] - tertile_means[1]\n",
    "\n",
    "# Step 4: Merge mean_diff with non_rem_bout_length\n",
    "bout_lengths = nrem_data_filtered[['non_rem_bout', 'non_rem_bout_length']].drop_duplicates()\n",
    "data_for_regression = pd.merge(\n",
    "    bout_lengths, \n",
    "    tertile_means[['mean_diff']], \n",
    "    on='non_rem_bout'\n",
    ")\n",
    "\n",
    "# Step 5: Perform linear regression using linregress\n",
    "x = data_for_regression['non_rem_bout_length']  # Independent variable\n",
    "y = data_for_regression['mean_diff']  # Dependent variable\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Print regression results\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"Slope: {slope:.4f}\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Standard Error: {std_err:.4f}\")\n",
    "\n",
    "# Scatter plot of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=x, y=y, color=\"blue\", s=100, alpha=0.5)\n",
    "\n",
    "# Plot regression line\n",
    "regression_line = intercept + slope * x\n",
    "plt.plot(x, regression_line, color=\"red\", linewidth=2)\n",
    "\n",
    "# Add R-squared and p-value annotations\n",
    "plt.text(\n",
    "    0.95, 0.95, \n",
    "    f\"$R^2$ = {r_value**2:.2f}\\nP-value = {p_value:.2f}\", \n",
    "    transform=plt.gca().transAxes, fontsize=12, verticalalignment=\"top\", color=\"black\"\n",
    ")\n",
    "\n",
    "# Customize plot aesthetics\n",
    "plt.title(\"NREM Bout Length vs Last to First Tertile 1/f Exponent Difference\", fontsize=18)\n",
    "plt.xlabel(\"Non-REM Bout Length\", fontsize=12)\n",
    "plt.ylabel(\"Exponent Difference (a.u.)\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Clean up plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine whether there is a difference in mean exponents in NREM bouts across 3 hour ZT blocks\n",
    "\n",
    "# Create ZT block column (e.g., ZT 0-3, 3-6, etc.)\n",
    "nrem_data_filtered['zt_block'] = nrem_data_filtered['ZT'] // 3\n",
    "\n",
    "# Group by subject and ZT block, calculate the mean avg_exps\n",
    "zt_block_means = (\n",
    "    nrem_data_filtered.groupby(['subject', 'zt_block'])['avg_exps']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Format ZT block intervals for clarity\n",
    "zt_block_means['zt_block_interval'] = zt_block_means['zt_block'].apply(lambda x: f\"ZT {x*3}-{(x+1)*3}\")\n",
    "\n",
    "# Display results\n",
    "print(zt_block_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom x-tick labels for ZT intervals\n",
    "zt_block_labels = [\n",
    "    \"0-3\", \"3-6\", \"6-9\", \"9-12\", \"12-15\", \"15-18\", \"18-21\", \"21-24\"\n",
    "]\n",
    "\n",
    "# Calculate the mean and SEM for each ZT block interval across subjects\n",
    "zt_block_summary = (\n",
    "    zt_block_means.groupby('zt_block')['avg_exps']\n",
    "    .agg(['mean', 'sem'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'mean_avg_exps', 'sem': 'sem_avg_exps'})\n",
    ")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatterplot for individual subjects\n",
    "scatter = sns.scatterplot(\n",
    "    data=zt_block_means,\n",
    "    x='zt_block',\n",
    "    y='avg_exps',\n",
    "    hue='subject',\n",
    "    palette='Set1',\n",
    "    alpha=0.6,\n",
    "    s=100,\n",
    ")\n",
    "\n",
    "# Line plot with mean and SEM error bars\n",
    "plt.errorbar(\n",
    "    x=zt_block_summary['zt_block'],\n",
    "    y=zt_block_summary['mean_avg_exps'],\n",
    "    fmt='-o',\n",
    "    color='black',\n",
    "    lw=2,\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "# Add plot details\n",
    "plt.title('NREM Bout 1/f Exponent Across 3-Hour ZT Blocks', fontsize=22)\n",
    "plt.xlabel('ZT Interval', fontsize=14)\n",
    "plt.ylabel('Exponent Value (a.u.)', fontsize=14)\n",
    "plt.xticks(\n",
    "    ticks=zt_block_summary['zt_block'], \n",
    "    labels=zt_block_labels, \n",
    "    rotation=0, \n",
    "    fontsize=12\n",
    ")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title='Subjects', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(title='Subjects', fontsize=12, loc='upper left')\n",
    "\n",
    "# Clean up plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "aov = pg.rm_anova(\n",
    "    data=zt_block_means,\n",
    "    dv='avg_exps',          # Dependent variable\n",
    "    within='zt_block',      # Within-subject factor\n",
    "    subject='subject',      # Subject identifier\n",
    "    detailed=True           # Print detailed results\n",
    ")\n",
    "print(\"Repeated Measures ANOVA Results:\")\n",
    "print(aov)\n",
    "\n",
    "# Perform pairwise comparisons with Bonferroni correction\n",
    "posthoc = pg.pairwise_ttests(\n",
    "    data=zt_block_means,\n",
    "    dv='avg_exps',           # Dependent variable\n",
    "    within='zt_block',       # Within-subject factor\n",
    "    subject='subject',       # Subject identifier\n",
    "    padjust='bonf'           # Bonferroni correction\n",
    ")\n",
    "print(\"\\nPost Hoc Pairwise Comparisons with Bonferroni Correction:\")\n",
    "print(posthoc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fooof_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
